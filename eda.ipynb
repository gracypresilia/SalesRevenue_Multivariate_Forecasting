{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8165e61",
   "metadata": {},
   "source": [
    "# Import all packages/library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "79fccb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1750354",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7facd4",
   "metadata": {},
   "source": [
    "Read the raw data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "89b33990",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('./data/retail_sales_synthetic.csv')\n",
    "df = raw_df.copy()  # Copy to ensure every change made in this code doesn't affect the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f5487e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will be truncated if we printed it as df.head() or df.describe() so we can't check (see) all columns.\n",
    "# In order to avoid that, we need to print it partially.\n",
    "n_col = len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "090e8d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Dataframe Head:\n",
      "         date  store_id store_type region    city  store_area_sqft product_id  \\\n",
      "0  2024-09-05  store_09          C   East  city_9             2287   prod_031   \n",
      "1  2022-10-24  store_02          C   East  city_2             2627   prod_041   \n",
      "2  2023-04-19  store_06          B   West  city_6             2547   prod_022   \n",
      "3  2024-06-22  store_06          B   West  city_6             2547   prod_037   \n",
      "4  2024-07-20  store_02          C   East  city_2             2627   prod_018   \n",
      "\n",
      "   category  base_price  final_price  discount_pct  \n",
      "0      Home       43.01        43.33           0.0  \n",
      "1    Sports      121.31        86.51          30.0  \n",
      "2  Clothing       11.10        11.05           0.0  \n",
      "3    Beauty      272.28       284.06           0.0  \n",
      "4      Home       56.11        56.58           0.0  \n",
      "   promotion  is_holiday  day_of_week  weekend  units_sold  returns  \\\n",
      "0          0           0            3        0           8        1   \n",
      "1          0           1            0        0           5        0   \n",
      "2          0           0            2        0           2        0   \n",
      "3          0           0            5        1           2        1   \n",
      "4          0           0            5        1           2        0   \n",
      "\n",
      "   net_units  revenue  net_revenue  avg_rating  online  \n",
      "0          7   346.65       303.32        3.41       1  \n",
      "1          5   432.56       432.56        3.59       0  \n",
      "2          2    22.09        22.09        3.86       0  \n",
      "3          1   568.12       284.06        4.71       0  \n",
      "4          2   113.16       113.16        3.86       0  \n"
     ]
    }
   ],
   "source": [
    "print('\\nInitial Dataframe Head:')\n",
    "print(df.head().iloc[:, :int(n_col/2)])\n",
    "print(df.head().iloc[:, int(n_col/2):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6096c8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Dataframe Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 164400 entries, 0 to 164399\n",
      "Data columns (total 22 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   date             164400 non-null  object \n",
      " 1   store_id         164400 non-null  object \n",
      " 2   store_type       164400 non-null  object \n",
      " 3   region           164400 non-null  object \n",
      " 4   city             164400 non-null  object \n",
      " 5   store_area_sqft  164400 non-null  int64  \n",
      " 6   product_id       164400 non-null  object \n",
      " 7   category         164400 non-null  object \n",
      " 8   base_price       164400 non-null  float64\n",
      " 9   final_price      164400 non-null  float64\n",
      " 10  discount_pct     164400 non-null  float64\n",
      " 11  promotion        164400 non-null  int64  \n",
      " 12  is_holiday       164400 non-null  int64  \n",
      " 13  day_of_week      164400 non-null  int64  \n",
      " 14  weekend          164400 non-null  int64  \n",
      " 15  units_sold       164400 non-null  int64  \n",
      " 16  returns          164400 non-null  int64  \n",
      " 17  net_units        164400 non-null  int64  \n",
      " 18  revenue          164400 non-null  float64\n",
      " 19  net_revenue      164400 non-null  float64\n",
      " 20  avg_rating       164400 non-null  float64\n",
      " 21  online           164400 non-null  int64  \n",
      "dtypes: float64(6), int64(9), object(7)\n",
      "memory usage: 27.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check the raw data information before preprocessing.\n",
    "print('\\nInitial Dataframe Information:')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0ec76ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Dataframe Numeric Stats:\n",
      "       store_area_sqft     base_price    final_price   discount_pct  \\\n",
      "count    164400.000000  164400.000000  164400.000000  164400.000000   \n",
      "mean       2440.700000      48.682199      46.781269       3.884519   \n",
      "std         317.638196      49.139032      47.473471       7.073051   \n",
      "min        1734.000000       5.800000       3.860000       0.000000   \n",
      "25%        2287.000000      17.750000      16.880000       0.000000   \n",
      "50%        2570.000000      31.030000      31.100000       0.000000   \n",
      "75%        2611.000000      59.100000      56.670000       5.000000   \n",
      "max        2904.000000     272.280000     293.690000      30.000000   \n",
      "\n",
      "           promotion     is_holiday    day_of_week  \n",
      "count  164400.000000  164400.000000  164400.000000  \n",
      "mean        0.079453       0.013686       3.000000  \n",
      "std         0.270445       0.116185       2.002286  \n",
      "min         0.000000       0.000000       0.000000  \n",
      "25%         0.000000       0.000000       1.000000  \n",
      "50%         0.000000       0.000000       3.000000  \n",
      "75%         0.000000       0.000000       5.000000  \n",
      "max         1.000000       1.000000       6.000000  \n",
      "             weekend     units_sold        returns      net_units  \\\n",
      "count  164400.000000  164400.000000  164400.000000  164400.000000   \n",
      "mean        0.286496       4.173650       0.083680       4.089970   \n",
      "std         0.452125       2.459849       0.290124       2.428308   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       2.000000       0.000000       2.000000   \n",
      "50%         0.000000       4.000000       0.000000       4.000000   \n",
      "75%         1.000000       6.000000       0.000000       5.000000   \n",
      "max         1.000000      27.000000       3.000000      27.000000   \n",
      "\n",
      "             revenue    net_revenue     avg_rating         online  \n",
      "count  164400.000000  164400.000000  164400.000000  164400.000000  \n",
      "mean      192.050357     188.190366       3.968690       0.249957  \n",
      "std       242.874412     238.727862       0.400809       0.432989  \n",
      "min         0.000000       0.000000       1.980000       0.000000  \n",
      "25%        54.060000      52.930000       3.700000       0.000000  \n",
      "50%       114.270000     112.020000       3.970000       0.000000  \n",
      "75%       233.120000     228.262500       4.240000       0.000000  \n",
      "max      3765.810000    3466.290000       5.000000       1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Check the current data numeric stats before preprocessing.\n",
    "print('\\nInitial Dataframe Numeric Stats:')\n",
    "print(df.describe().iloc[:, :int(n_col/3)])\n",
    "print(df.describe().iloc[:, int(n_col/3):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37499c4a",
   "metadata": {},
   "source": [
    "As shown above, the data is already clean and ready to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fecc1c",
   "metadata": {},
   "source": [
    "# EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b161bb51",
   "metadata": {},
   "source": [
    "## 1. Does the presence of holiday affect overall sales and revenue, both daily and monthly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb0efed",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "107fda33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  is_holiday  net_units  net_revenue\n",
      "0  2024-09-05           0          7       303.32\n",
      "1  2022-10-24           1          5       432.56\n",
      "2  2023-04-19           0          2        22.09\n",
      "3  2024-06-22           0          1       284.06\n",
      "4  2024-07-20           0          2       113.16\n"
     ]
    }
   ],
   "source": [
    "# Each rows are proven unique by the previous step so we can exclude the ID columns in this section.\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_1 = df[['date','is_holiday','net_units','net_revenue']].copy()\n",
    "print(df_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6558c448",
   "metadata": {},
   "source": [
    "### Holiday Effect Towards Daily Sales and Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42d468",
   "metadata": {},
   "source": [
    "Sum sales (units) and revenue of all stores and products each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c95a4434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            is_holiday  net_units  net_revenue\n",
      "date                                          \n",
      "2022-01-01           0        633     32625.87\n",
      "2022-01-02           0        636     31625.80\n",
      "2022-01-03           0        574     30254.72\n",
      "2022-01-04           0        532     26296.65\n",
      "2022-01-05           0        568     25624.26\n"
     ]
    }
   ],
   "source": [
    "df_1 = df_1.groupby(df_1['date']).sum()\n",
    "# The above line will sum all data except `date` so `is_holiday` were also summed.\n",
    "# However, `is_holiday` is conditional data and is more suitable to represent as binary in a day-by-day data.\n",
    "df_1.loc[df_1['is_holiday'] > 0, 'is_holiday'] = 1\n",
    "print(df_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa2ce65",
   "metadata": {},
   "source": [
    "Find the correlation coefficients between variables (`is_holiday`, `net_units`, and `net_revenue`) to analyze the effect of holiday to daily sales and revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0fb4dabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             is_holiday  net_units  net_revenue\n",
      "is_holiday     1.000000   0.169136     0.141445\n",
      "net_units      0.169136   1.000000     0.919873\n",
      "net_revenue    0.141445   0.919873     1.000000\n"
     ]
    }
   ],
   "source": [
    "corr_1_1 = df_1[['is_holiday', 'net_units', 'net_revenue']].corr()\n",
    "print(corr_1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3a27c3",
   "metadata": {},
   "source": [
    "Based on the results, the presence of holiday doesn't significantly affect the overall daily sales and revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c37493",
   "metadata": {},
   "source": [
    "### Holiday Effect Towards Monthly Sales and Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d40dde",
   "metadata": {},
   "source": [
    "Every dates in the current data are already unique so we can erase the day in the `date` data to support monthly-based analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "064a4ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         is_holiday  net_units  net_revenue\n",
      "date                                       \n",
      "2022-01           0        633     32625.87\n",
      "2022-01           0        636     31625.80\n",
      "2022-01           0        574     30254.72\n",
      "2022-01           0        532     26296.65\n",
      "2022-01           0        568     25624.26\n"
     ]
    }
   ],
   "source": [
    "df_1.index = df_1.index.astype(str).str.replace(r'-\\d{2}$', '', regex=True)\n",
    "print(df_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba6c05",
   "metadata": {},
   "source": [
    "Group (sum) the numeric data based on `date` to earn monthly net sales and revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "549a87db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         is_holiday  net_units  net_revenue\n",
      "date                                       \n",
      "2022-01           1      18498    860972.53\n",
      "2022-02           0      16240    743945.03\n",
      "2022-03           1      18163    833257.90\n",
      "2022-04           0      17575    830541.04\n",
      "2022-05           0      18032    811823.17\n"
     ]
    }
   ],
   "source": [
    "df_1 = df_1.groupby(df_1.index).sum()\n",
    "# In this section, `is_holiday` is no longer conditional and is expected to be summed as a representation for total holiday-days in a month.\n",
    "print(df_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d256a1a9",
   "metadata": {},
   "source": [
    "Find the correlation coefficients between variables (`is_holiday`, `net_units`, and `net_revenue`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5ee86260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             is_holiday  net_units  net_revenue\n",
      "is_holiday     1.000000   0.218785     0.222019\n",
      "net_units      0.218785   1.000000     0.994426\n",
      "net_revenue    0.222019   0.994426     1.000000\n"
     ]
    }
   ],
   "source": [
    "corr_1_2 = df_1[['is_holiday', 'net_units', 'net_revenue']].corr()\n",
    "print(corr_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18134f6f",
   "metadata": {},
   "source": [
    "Based on the results, the presence of holiday doesn't significantly affect the overall monthly sales and revenue. However, the effect shows more than the daily analysis in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eb2267",
   "metadata": {},
   "source": [
    "## 2. Is there any change in product's category trend during no-holiday months and holiday months?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8053316",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "269d7e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  is_holiday  category  net_units\n",
      "0  2024-09-05           0      Home          7\n",
      "1  2022-10-24           1    Sports          5\n",
      "2  2023-04-19           0  Clothing          2\n",
      "3  2024-06-22           0    Beauty          1\n",
      "4  2024-07-20           0      Home          2\n"
     ]
    }
   ],
   "source": [
    "# Each rows are proven unique by the previous step so we can exclude the ID columns in this section.\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_2 = df[['date','is_holiday','category','net_units']].copy()\n",
    "print(df_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd12ce",
   "metadata": {},
   "source": [
    "Every dates in the current data are already uniquely paired with each category so we can erase the day in the `date` data to support monthly-based analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "82749c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date  is_holiday  category  net_units\n",
      "0  2024-09           0      Home          7\n",
      "1  2022-10           1    Sports          5\n",
      "2  2023-04           0  Clothing          2\n",
      "3  2024-06           0    Beauty          1\n",
      "4  2024-07           0      Home          2\n"
     ]
    }
   ],
   "source": [
    "df_2['date'] = df_2['date'].astype(str).str.replace(r'-\\d{2}$', '', regex=True)\n",
    "print(df_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e5e44",
   "metadata": {},
   "source": [
    "Count `net_units` by month and product's category while keeping the `is_holiday` properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6baa407f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date     category  is_holiday  net_units\n",
      "0  2022-01       Beauty           1       1670\n",
      "1  2022-01     Clothing           1       6177\n",
      "2  2022-01  Electronics           1       3936\n",
      "3  2022-01         Home           1       5372\n",
      "4  2022-01       Sports           1       1343\n"
     ]
    }
   ],
   "source": [
    "df_2 = df_2.groupby(['date', 'category'], as_index=False)[['is_holiday','net_units']].sum()\n",
    "# The above line will sum `is_holiday` and `net_units` data based on unique pairs of `date` and `category`.\n",
    "# However, in this section, we need `is_holiday` as a conditional data so it is more suitable to represent as binary.\n",
    "df_2.loc[df_2['is_holiday'] > 0, 'is_holiday'] = 1\n",
    "print(df_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a5784",
   "metadata": {},
   "source": [
    "Only returns the highest sales product's category for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "624a4b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date  category  is_holiday  net_units\n",
      "1   2022-01  Clothing           1       6177\n",
      "6   2022-02  Clothing           0       5343\n",
      "11  2022-03  Clothing           1       6203\n",
      "16  2022-04  Clothing           0       6069\n",
      "21  2022-05  Clothing           0       6079\n"
     ]
    }
   ],
   "source": [
    "df_2 = df_2.loc[df_2.groupby('date')['net_units'].idxmax()]\n",
    "print(df_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00089934",
   "metadata": {},
   "source": [
    "Only returns the mode of the highest sales product's category across all of the no-holiday months and all of the holiday months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ec2e2dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_holiday\n",
      "0    Clothing\n",
      "1    Clothing\n",
      "Name: category, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_2 = df_2.groupby('is_holiday')['category'].agg(lambda x: x.mode()[0])\n",
    "print(df_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f96643",
   "metadata": {},
   "source": [
    "As seen in the two latest dataframes, there's no change in product's category trend during no-holiday months and holiday months. Both product's category trends are clothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ccc942",
   "metadata": {},
   "source": [
    "## 3. Does the weekend status affect overall daily sales and revenue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df8fc63",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "baa42018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  weekend  net_units  net_revenue\n",
      "0  2024-09-05        0          7       303.32\n",
      "1  2022-10-24        0          5       432.56\n",
      "2  2023-04-19        0          2        22.09\n",
      "3  2024-06-22        1          1       284.06\n",
      "4  2024-07-20        1          2       113.16\n"
     ]
    }
   ],
   "source": [
    "# Each rows are proven unique by the previous step so we can exclude the ID columns in this section.\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_3 = df[['date','weekend','net_units','net_revenue']].copy()\n",
    "print(df_3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a78aec",
   "metadata": {},
   "source": [
    "Sum sales (units) and revenue of all stores and products each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9cdfa0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            weekend  net_units  net_revenue\n",
      "date                                       \n",
      "2022-01-01        1        633     32625.87\n",
      "2022-01-02        1        636     31625.80\n",
      "2022-01-03        0        574     30254.72\n",
      "2022-01-04        0        532     26296.65\n",
      "2022-01-05        0        568     25624.26\n"
     ]
    }
   ],
   "source": [
    "df_3 = df_3.groupby(df_3['date']).sum()\n",
    "# The above line will sum all data except `date` so `weekend` were also summed.\n",
    "# However, `weekend` is conditional data and is more suitable to represent as binary in a day-by-day data.\n",
    "df_3.loc[df_3['weekend'] > 0, 'weekend'] = 1\n",
    "print(df_3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3c25cf",
   "metadata": {},
   "source": [
    "Find the correlation coefficients between variables (`weekend`, `net_units`, and `net_revenue`) to analyze the effect of weekend to daily sales and revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8e281bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              weekend  net_units  net_revenue\n",
      "weekend      1.000000   0.511264     0.462136\n",
      "net_units    0.511264   1.000000     0.919873\n",
      "net_revenue  0.462136   0.919873     1.000000\n"
     ]
    }
   ],
   "source": [
    "corr_2 = df_3[['weekend', 'net_units', 'net_revenue']].corr()\n",
    "print(corr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fe7deb",
   "metadata": {},
   "source": [
    "Based on the results, the weekend status quite significantly affect the overall daily sales and revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa5abc",
   "metadata": {},
   "source": [
    "## 4. How is the overall day-by-day sales and revenue trend during a week?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df23e625",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d72a92d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   day_of_week  net_units  net_revenue\n",
      "0            3          7       303.32\n",
      "1            0          5       432.56\n",
      "2            2          2        22.09\n",
      "3            5          1       284.06\n",
      "4            5          2       113.16\n"
     ]
    }
   ],
   "source": [
    "# Each rows are proven unique by the previous step so we can exclude the ID columns in this section.\n",
    "# Because this section analyze day or `day_of_week` instead of `date`, we can also exclide the `date` column.\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_4 = df[['day_of_week','net_units','net_revenue']].copy()\n",
    "print(df_4.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df807cf",
   "metadata": {},
   "source": [
    "Find the average values of sales and revenue for each day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "62e243ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             net_units  net_revenue\n",
      "day_of_week                        \n",
      "0             3.825563   177.054874\n",
      "1             3.819278   175.540487\n",
      "2             3.849615   176.279568\n",
      "3             3.831197   175.841911\n",
      "4             3.873120   178.832584\n",
      "5             4.691125   214.380471\n",
      "6             4.735329   219.188544\n"
     ]
    }
   ],
   "source": [
    "df_4 = df_4.groupby(df_4['day_of_week']).mean()\n",
    "print(df_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086986a5",
   "metadata": {},
   "source": [
    "The result shows that, during the weekend, the sales and revenue were higher. This shows a consistent result between this section and previous section, the weekend status quite significantly affect the overall daily sales and revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934f99d",
   "metadata": {},
   "source": [
    "## 5. Does the store type and area affect the customer experiences, which lead to store's sales and revenue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998dbd79",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b613be1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  store_type  store_area_sqft  avg_rating  net_units  net_revenue\n",
      "0          C             2287        3.41          7       303.32\n",
      "1          C             2627        3.59          5       432.56\n",
      "2          B             2547        3.86          2        22.09\n",
      "3          B             2547        4.71          1       284.06\n",
      "4          C             2627        3.86          2       113.16\n"
     ]
    }
   ],
   "source": [
    "# Each rows are proven unique by the previous step so we can exclude the `date` and ID columns in this section.\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_5 = df[['store_type','store_area_sqft','avg_rating','net_units','net_revenue']].copy()\n",
    "print(df_5.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ea261",
   "metadata": {},
   "source": [
    "Find the average values of customer experiences, sales, and revenue for each store type and area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "73b5c3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  store_type  store_area_sqft  avg_rating  net_units  net_revenue\n",
      "0          A             1734    3.972809   4.283577   196.241209\n",
      "1          A             2593    3.964456   4.324088   200.346071\n",
      "2          A             2596    3.968857   4.059367   186.223064\n",
      "3          B             2547    3.965058   3.888564   175.711395\n",
      "4          C             2055    3.968860   4.095438   190.132041\n",
      "5          C             2287    3.968108   3.859124   178.184290\n",
      "6          C             2453    3.968673   4.051886   186.245386\n",
      "7          C             2611    3.970072   3.870073   177.580783\n",
      "8          C             2627    3.965832   4.363808   202.385544\n",
      "9          C             2904    3.974178   4.103771   188.853874\n"
     ]
    }
   ],
   "source": [
    "df_5 = df_5.groupby(['store_type', 'store_area_sqft'], as_index=False)[['avg_rating','net_units','net_revenue']].mean()\n",
    "print(df_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6df5ff6",
   "metadata": {},
   "source": [
    "### Store Type Effect Towards Average Customer Experiences, Sales, and Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8afab2",
   "metadata": {},
   "source": [
    "Find the average values of customer experiences, sales, and revenue for each store type only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "eb7d2183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            avg_rating  net_units  net_revenue\n",
      "store_type                                    \n",
      "A             3.968707   4.222344   194.270115\n",
      "B             3.965058   3.888564   175.711395\n",
      "C             3.969287   4.057350   187.230320\n"
     ]
    }
   ],
   "source": [
    "df_5_type = df_5.drop(columns='store_area_sqft').copy()\n",
    "df_5_type = df_5_type.groupby(df_5_type['store_type']).mean()\n",
    "print(df_5_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b5d8d4",
   "metadata": {},
   "source": [
    "The result above shows that store type, though it doesn't significantly affect customer experiences, quite significantly affect store's sales and revenue. Store type C has the highest rank, but store type A has the highest net sales and revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa874f76",
   "metadata": {},
   "source": [
    "### Store Area (in sqft) Effect Towards Average Customer Experiences, Sales, and Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d00088c",
   "metadata": {},
   "source": [
    "Find the correlation coefficients between `store_area_sqft`, `avg_rating`, `net_units`, and `net_revenue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d769bba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 store_area_sqft  avg_rating  net_units  net_revenue\n",
      "store_area_sqft         1.000000   -0.174085  -0.132697    -0.125751\n",
      "avg_rating             -0.174085    1.000000  -0.065062    -0.070525\n",
      "net_units              -0.132697   -0.065062   1.000000     0.990896\n",
      "net_revenue            -0.125751   -0.070525   0.990896     1.000000\n"
     ]
    }
   ],
   "source": [
    "df_5_area = df_5[['store_area_sqft', 'avg_rating', 'net_units', 'net_revenue']].corr()\n",
    "print(df_5_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a32727",
   "metadata": {},
   "source": [
    "The result above shows that store area doesn't significantly affect either customer experiences, sales, nor revenue. However, it shows a unique correlation which a bigger store area results to a lower rating, sales, and revenue. In addition, surprisingly, customer experiences also doesn't significantly affect either sales nor revenue and is on negative correlation, which means a higher rating results to lower sales and revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d59777",
   "metadata": {},
   "source": [
    "## 6. Which category of product is the most popular in each city month-by-month?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df60505",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0f37d795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date    city  category  net_units\n",
      "0  2024-09-05  city_9      Home          7\n",
      "1  2022-10-24  city_2    Sports          5\n",
      "2  2023-04-19  city_6  Clothing          2\n",
      "3  2024-06-22  city_6    Beauty          1\n",
      "4  2024-07-20  city_2      Home          2\n"
     ]
    }
   ],
   "source": [
    "# Each rows are proven unique by the previous step so we can exclude the `date` and ID columns in this section.\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_6 = df[['date','city','category','net_units']].copy()\n",
    "print(df_6.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1156fab1",
   "metadata": {},
   "source": [
    "Every dates in the current data are already uniquely paired with each category so we can erase the day in the `date` data to support monthly-based analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1031f9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date    city  category  net_units\n",
      "0       2024-09  city_9      Home          7\n",
      "1       2022-10  city_2    Sports          5\n",
      "2       2023-04  city_6  Clothing          2\n",
      "3       2024-06  city_6    Beauty          1\n",
      "4       2024-07  city_2      Home          2\n",
      "...         ...     ...       ...        ...\n",
      "164395  2024-03  city_2    Sports          6\n",
      "164396  2023-11  city_3      Home          2\n",
      "164397  2024-05  city_6      Home          4\n",
      "164398  2024-09  city_2    Sports          1\n",
      "164399  2024-03  city_1    Beauty          5\n",
      "\n",
      "[164400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_6['date'] = df_6['date'].astype(str).str.replace(r'-\\d{2}$', '', regex=True)\n",
    "print(df_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145aa3f6",
   "metadata": {},
   "source": [
    "Count `net_units` by month and product's category while keeping the `city` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "483b5f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date category     city  net_units\n",
      "0  2022-01   Beauty   city_1        176\n",
      "1  2022-01   Beauty  city_10        151\n",
      "2  2022-01   Beauty   city_2        150\n",
      "3  2022-01   Beauty   city_3        163\n",
      "4  2022-01   Beauty   city_4        181\n"
     ]
    }
   ],
   "source": [
    "df_6 = df_6.groupby(['date', 'category','city'], as_index=False)[['net_units']].sum()\n",
    "# The above line will sum `net_units` data based on unique pairs of `date`, `category`, and 'city'.\n",
    "print(df_6.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db81167",
   "metadata": {},
   "source": [
    "Separate data by city to support city-based analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fc98a8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City 1:\n",
      "        date     category  net_units\n",
      "0   2022-01       Beauty        176\n",
      "10  2022-01     Clothing        647\n",
      "20  2022-01  Electronics        404\n",
      "30  2022-01         Home        561\n",
      "40  2022-01       Sports         92\n",
      "City 2:\n",
      "        date     category  net_units\n",
      "2   2022-01       Beauty        150\n",
      "12  2022-01     Clothing        678\n",
      "22  2022-01  Electronics        414\n",
      "32  2022-01         Home        549\n",
      "42  2022-01       Sports        147\n",
      "City 3:\n",
      "        date     category  net_units\n",
      "3   2022-01       Beauty        163\n",
      "13  2022-01     Clothing        536\n",
      "23  2022-01  Electronics        370\n",
      "33  2022-01         Home        556\n",
      "43  2022-01       Sports        121\n",
      "City 4:\n",
      "        date     category  net_units\n",
      "4   2022-01       Beauty        181\n",
      "14  2022-01     Clothing        613\n",
      "24  2022-01  Electronics        339\n",
      "34  2022-01         Home        510\n",
      "44  2022-01       Sports        154\n",
      "City 5:\n",
      "        date     category  net_units\n",
      "5   2022-01       Beauty        174\n",
      "15  2022-01     Clothing        700\n",
      "25  2022-01  Electronics        378\n",
      "35  2022-01         Home        531\n",
      "45  2022-01       Sports        135\n",
      "City 6:\n",
      "        date     category  net_units\n",
      "6   2022-01       Beauty        163\n",
      "16  2022-01     Clothing        528\n",
      "26  2022-01  Electronics        420\n",
      "36  2022-01         Home        566\n",
      "46  2022-01       Sports        146\n",
      "City 7:\n",
      "        date     category  net_units\n",
      "7   2022-01       Beauty        180\n",
      "17  2022-01     Clothing        609\n",
      "27  2022-01  Electronics        424\n",
      "37  2022-01         Home        525\n",
      "47  2022-01       Sports        187\n",
      "City 8:\n",
      "        date     category  net_units\n",
      "8   2022-01       Beauty        197\n",
      "18  2022-01     Clothing        640\n",
      "28  2022-01  Electronics        383\n",
      "38  2022-01         Home        528\n",
      "48  2022-01       Sports        136\n",
      "City 9:\n",
      "        date     category  net_units\n",
      "9   2022-01       Beauty        135\n",
      "19  2022-01     Clothing        529\n",
      "29  2022-01  Electronics        439\n",
      "39  2022-01         Home        522\n",
      "49  2022-01       Sports         97\n",
      "City 10:\n",
      "        date     category  net_units\n",
      "1   2022-01       Beauty        151\n",
      "11  2022-01     Clothing        697\n",
      "21  2022-01  Electronics        365\n",
      "31  2022-01         Home        524\n",
      "41  2022-01       Sports        128\n"
     ]
    }
   ],
   "source": [
    "df_6_1 = df_6[df_6['city'] == 'city_1'].drop(columns='city')\n",
    "print('City 1:\\n',df_6_1.head())\n",
    "df_6_2 = df_6[df_6['city'] == 'city_2'].drop(columns='city')\n",
    "print('City 2:\\n',df_6_2.head())\n",
    "df_6_3 = df_6[df_6['city'] == 'city_3'].drop(columns='city')\n",
    "print('City 3:\\n',df_6_3.head())\n",
    "df_6_4 = df_6[df_6['city'] == 'city_4'].drop(columns='city')\n",
    "print('City 4:\\n',df_6_4.head())\n",
    "df_6_5 = df_6[df_6['city'] == 'city_5'].drop(columns='city')\n",
    "print('City 5:\\n',df_6_5.head())\n",
    "df_6_6 = df_6[df_6['city'] == 'city_6'].drop(columns='city')\n",
    "print('City 6:\\n',df_6_6.head())\n",
    "df_6_7 = df_6[df_6['city'] == 'city_7'].drop(columns='city')\n",
    "print('City 7:\\n',df_6_7.head())\n",
    "df_6_8 = df_6[df_6['city'] == 'city_8'].drop(columns='city')\n",
    "print('City 8:\\n',df_6_8.head())\n",
    "df_6_9 = df_6[df_6['city'] == 'city_9'].drop(columns='city')\n",
    "print('City 9:\\n',df_6_9.head())\n",
    "df_6_10 = df_6[df_6['city'] == 'city_10'].drop(columns='city')\n",
    "print('City 10:\\n',df_6_10.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c679b1",
   "metadata": {},
   "source": [
    "Returns the highest sales product's category for each pair of month and place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "24a1360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City 1:\n",
      "          date  category  net_units\n",
      "10    2022-01  Clothing        647\n",
      "60    2022-02  Clothing        579\n",
      "110   2022-03  Clothing        697\n",
      "160   2022-04  Clothing        625\n",
      "210   2022-05  Clothing        571\n",
      "260   2022-06  Clothing        530\n",
      "310   2022-07  Clothing        531\n",
      "360   2022-08  Clothing        633\n",
      "410   2022-09  Clothing        632\n",
      "460   2022-10  Clothing        639\n",
      "510   2022-11  Clothing        871\n",
      "560   2022-12  Clothing        860\n",
      "610   2023-01  Clothing        661\n",
      "660   2023-02  Clothing        573\n",
      "710   2023-03  Clothing        575\n",
      "760   2023-04  Clothing        609\n",
      "810   2023-05  Clothing        558\n",
      "860   2023-06  Clothing        551\n",
      "910   2023-07  Clothing        588\n",
      "960   2023-08  Clothing        561\n",
      "1010  2023-09  Clothing        578\n",
      "1060  2023-10  Clothing        623\n",
      "1130  2023-11      Home        719\n",
      "1180  2023-12      Home        916\n",
      "1210  2024-01  Clothing        596\n",
      "1260  2024-02  Clothing        529\n",
      "1310  2024-03  Clothing        622\n",
      "1360  2024-04  Clothing        608\n",
      "1410  2024-05  Clothing        658\n",
      "1460  2024-06  Clothing        509\n",
      "1510  2024-07  Clothing        644\n",
      "1580  2024-08      Home        557\n",
      "1610  2024-09  Clothing        584\n",
      "1660  2024-10  Clothing        629\n",
      "1710  2024-11  Clothing        852\n",
      "1760  2024-12  Clothing        844\n",
      "\n",
      "City 2:\n",
      "          date  category  net_units\n",
      "12    2022-01  Clothing        678\n",
      "62    2022-02  Clothing        566\n",
      "112   2022-03  Clothing        644\n",
      "162   2022-04  Clothing        670\n",
      "212   2022-05  Clothing        732\n",
      "262   2022-06  Clothing        554\n",
      "312   2022-07  Clothing        655\n",
      "362   2022-08  Clothing        579\n",
      "412   2022-09  Clothing        696\n",
      "462   2022-10  Clothing        690\n",
      "512   2022-11  Clothing        912\n",
      "562   2022-12  Clothing        966\n",
      "612   2023-01  Clothing        718\n",
      "662   2023-02  Clothing        583\n",
      "712   2023-03  Clothing        684\n",
      "762   2023-04  Clothing        646\n",
      "812   2023-05  Clothing        749\n",
      "882   2023-06      Home        546\n",
      "912   2023-07  Clothing        599\n",
      "962   2023-08  Clothing        595\n",
      "1032  2023-09      Home        660\n",
      "1062  2023-10  Clothing        631\n",
      "1112  2023-11  Clothing        829\n",
      "1162  2023-12  Clothing        930\n",
      "1212  2024-01  Clothing        670\n",
      "1262  2024-02  Clothing        585\n",
      "1312  2024-03  Clothing        716\n",
      "1362  2024-04  Clothing        673\n",
      "1412  2024-05  Clothing        649\n",
      "1462  2024-06  Clothing        622\n",
      "1512  2024-07  Clothing        644\n",
      "1562  2024-08  Clothing        691\n",
      "1612  2024-09  Clothing        630\n",
      "1662  2024-10  Clothing        671\n",
      "1712  2024-11  Clothing        827\n",
      "1782  2024-12      Home        947\n",
      "\n",
      "City 3:\n",
      "          date  category  net_units\n",
      "33    2022-01      Home        556\n",
      "63    2022-02  Clothing        459\n",
      "113   2022-03  Clothing        539\n",
      "163   2022-04  Clothing        561\n",
      "233   2022-05      Home        514\n",
      "283   2022-06      Home        504\n",
      "313   2022-07  Clothing        520\n",
      "363   2022-08  Clothing        570\n",
      "413   2022-09  Clothing        613\n",
      "463   2022-10  Clothing        593\n",
      "513   2022-11  Clothing        788\n",
      "563   2022-12  Clothing        839\n",
      "613   2023-01  Clothing        511\n",
      "663   2023-02  Clothing        527\n",
      "733   2023-03      Home        561\n",
      "763   2023-04  Clothing        570\n",
      "813   2023-05  Clothing        587\n",
      "863   2023-06  Clothing        571\n",
      "913   2023-07  Clothing        518\n",
      "963   2023-08  Clothing        560\n",
      "1013  2023-09  Clothing        596\n",
      "1063  2023-10  Clothing        622\n",
      "1113  2023-11  Clothing        721\n",
      "1183  2023-12      Home        788\n",
      "1213  2024-01  Clothing        560\n",
      "1263  2024-02  Clothing        584\n",
      "1313  2024-03  Clothing        586\n",
      "1363  2024-04  Clothing        635\n",
      "1413  2024-05  Clothing        603\n",
      "1463  2024-06  Clothing        567\n",
      "1513  2024-07  Clothing        511\n",
      "1583  2024-08      Home        512\n",
      "1613  2024-09  Clothing        578\n",
      "1663  2024-10  Clothing        531\n",
      "1713  2024-11  Clothing        764\n",
      "1763  2024-12  Clothing        769\n",
      "\n",
      "City 4:\n",
      "          date  category  net_units\n",
      "14    2022-01  Clothing        613\n",
      "64    2022-02  Clothing        523\n",
      "114   2022-03  Clothing        651\n",
      "164   2022-04  Clothing        604\n",
      "214   2022-05  Clothing        709\n",
      "264   2022-06  Clothing        552\n",
      "334   2022-07      Home        595\n",
      "364   2022-08  Clothing        614\n",
      "434   2022-09      Home        526\n",
      "464   2022-10  Clothing        687\n",
      "514   2022-11  Clothing        862\n",
      "564   2022-12  Clothing        916\n",
      "614   2023-01  Clothing        679\n",
      "664   2023-02  Clothing        576\n",
      "714   2023-03  Clothing        565\n",
      "764   2023-04  Clothing        577\n",
      "814   2023-05  Clothing        645\n",
      "864   2023-06  Clothing        534\n",
      "934   2023-07      Home        572\n",
      "964   2023-08  Clothing        571\n",
      "1014  2023-09  Clothing        629\n",
      "1064  2023-10  Clothing        618\n",
      "1114  2023-11  Clothing        820\n",
      "1164  2023-12  Clothing        844\n",
      "1214  2024-01  Clothing        649\n",
      "1264  2024-02  Clothing        619\n",
      "1314  2024-03  Clothing        644\n",
      "1364  2024-04  Clothing        608\n",
      "1414  2024-05  Clothing        638\n",
      "1464  2024-06  Clothing        645\n",
      "1534  2024-07      Home        579\n",
      "1564  2024-08  Clothing        587\n",
      "1614  2024-09  Clothing        640\n",
      "1664  2024-10  Clothing        685\n",
      "1714  2024-11  Clothing        801\n",
      "1764  2024-12  Clothing        904\n",
      "\n",
      "City 5:\n",
      "          date  category  net_units\n",
      "15    2022-01  Clothing        700\n",
      "85    2022-02      Home        510\n",
      "115   2022-03  Clothing        693\n",
      "165   2022-04  Clothing        589\n",
      "215   2022-05  Clothing        640\n",
      "265   2022-06  Clothing        586\n",
      "315   2022-07  Clothing        592\n",
      "365   2022-08  Clothing        610\n",
      "415   2022-09  Clothing        642\n",
      "465   2022-10  Clothing        626\n",
      "515   2022-11  Clothing       1001\n",
      "565   2022-12  Clothing        885\n",
      "615   2023-01  Clothing        651\n",
      "665   2023-02  Clothing        544\n",
      "715   2023-03  Clothing        641\n",
      "765   2023-04  Clothing        647\n",
      "815   2023-05  Clothing        623\n",
      "865   2023-06  Clothing        633\n",
      "915   2023-07  Clothing        645\n",
      "985   2023-08      Home        590\n",
      "1015  2023-09  Clothing        607\n",
      "1065  2023-10  Clothing        635\n",
      "1115  2023-11  Clothing        825\n",
      "1165  2023-12  Clothing        985\n",
      "1215  2024-01  Clothing        615\n",
      "1265  2024-02  Clothing        605\n",
      "1315  2024-03  Clothing        719\n",
      "1365  2024-04  Clothing        579\n",
      "1415  2024-05  Clothing        625\n",
      "1485  2024-06      Home        615\n",
      "1515  2024-07  Clothing        608\n",
      "1565  2024-08  Clothing        656\n",
      "1615  2024-09  Clothing        682\n",
      "1665  2024-10  Clothing        624\n",
      "1715  2024-11  Clothing        979\n",
      "1765  2024-12  Clothing       1005\n",
      "\n",
      "City 6:\n",
      "          date  category  net_units\n",
      "36    2022-01      Home        566\n",
      "86    2022-02      Home        496\n",
      "136   2022-03      Home        548\n",
      "166   2022-04  Clothing        566\n",
      "216   2022-05  Clothing        548\n",
      "266   2022-06  Clothing        643\n",
      "336   2022-07      Home        551\n",
      "366   2022-08  Clothing        607\n",
      "416   2022-09  Clothing        583\n",
      "466   2022-10  Clothing        577\n",
      "516   2022-11  Clothing        841\n",
      "566   2022-12  Clothing        869\n",
      "616   2023-01  Clothing        657\n",
      "666   2023-02  Clothing        545\n",
      "716   2023-03  Clothing        683\n",
      "766   2023-04  Clothing        524\n",
      "816   2023-05  Clothing        604\n",
      "866   2023-06  Clothing        544\n",
      "936   2023-07      Home        513\n",
      "966   2023-08  Clothing        563\n",
      "1016  2023-09  Clothing        574\n",
      "1066  2023-10  Clothing        555\n",
      "1116  2023-11  Clothing        818\n",
      "1166  2023-12  Clothing        814\n",
      "1216  2024-01  Clothing        543\n",
      "1266  2024-02  Clothing        576\n",
      "1316  2024-03  Clothing        626\n",
      "1366  2024-04  Clothing        535\n",
      "1416  2024-05  Clothing        602\n",
      "1466  2024-06  Clothing        535\n",
      "1516  2024-07  Clothing        548\n",
      "1586  2024-08      Home        546\n",
      "1616  2024-09  Clothing        567\n",
      "1666  2024-10  Clothing        587\n",
      "1736  2024-11      Home        763\n",
      "1786  2024-12      Home        807\n",
      "\n",
      "City 7:\n",
      "          date  category  net_units\n",
      "17    2022-01  Clothing        609\n",
      "67    2022-02  Clothing        537\n",
      "117   2022-03  Clothing        659\n",
      "167   2022-04  Clothing        630\n",
      "217   2022-05  Clothing        613\n",
      "287   2022-06      Home        473\n",
      "317   2022-07  Clothing        609\n",
      "367   2022-08  Clothing        537\n",
      "417   2022-09  Clothing        587\n",
      "467   2022-10  Clothing        655\n",
      "517   2022-11  Clothing        888\n",
      "567   2022-12  Clothing        885\n",
      "617   2023-01  Clothing        636\n",
      "667   2023-02  Clothing        527\n",
      "737   2023-03      Home        545\n",
      "767   2023-04  Clothing        613\n",
      "817   2023-05  Clothing        593\n",
      "867   2023-06  Clothing        561\n",
      "917   2023-07  Clothing        612\n",
      "967   2023-08  Clothing        625\n",
      "1037  2023-09      Home        600\n",
      "1067  2023-10  Clothing        595\n",
      "1137  2023-11      Home        812\n",
      "1167  2023-12  Clothing        795\n",
      "1217  2024-01  Clothing        624\n",
      "1267  2024-02  Clothing        533\n",
      "1317  2024-03  Clothing        591\n",
      "1367  2024-04  Clothing        585\n",
      "1417  2024-05  Clothing        619\n",
      "1487  2024-06      Home        551\n",
      "1517  2024-07  Clothing        714\n",
      "1567  2024-08  Clothing        592\n",
      "1617  2024-09  Clothing        555\n",
      "1667  2024-10  Clothing        636\n",
      "1737  2024-11      Home        839\n",
      "1767  2024-12  Clothing        894\n",
      "\n",
      "City 8:\n",
      "          date  category  net_units\n",
      "18    2022-01  Clothing        640\n",
      "68    2022-02  Clothing        660\n",
      "118   2022-03  Clothing        648\n",
      "188   2022-04      Home        530\n",
      "238   2022-05      Home        664\n",
      "268   2022-06  Clothing        536\n",
      "318   2022-07  Clothing        556\n",
      "368   2022-08  Clothing        644\n",
      "418   2022-09  Clothing        710\n",
      "468   2022-10  Clothing        643\n",
      "518   2022-11  Clothing        912\n",
      "568   2022-12  Clothing       1078\n",
      "618   2023-01  Clothing        684\n",
      "688   2023-02      Home        619\n",
      "718   2023-03  Clothing        648\n",
      "768   2023-04  Clothing        579\n",
      "818   2023-05  Clothing        657\n",
      "868   2023-06  Clothing        613\n",
      "918   2023-07  Clothing        592\n",
      "968   2023-08  Clothing        643\n",
      "1018  2023-09  Clothing        572\n",
      "1088  2023-10      Home        635\n",
      "1118  2023-11  Clothing        919\n",
      "1168  2023-12  Clothing        947\n",
      "1218  2024-01  Clothing        653\n",
      "1268  2024-02  Clothing        569\n",
      "1338  2024-03      Home        627\n",
      "1368  2024-04  Clothing        613\n",
      "1418  2024-05  Clothing        562\n",
      "1468  2024-06  Clothing        607\n",
      "1518  2024-07  Clothing        581\n",
      "1568  2024-08  Clothing        635\n",
      "1618  2024-09  Clothing        616\n",
      "1688  2024-10      Home        627\n",
      "1718  2024-11  Clothing        884\n",
      "1768  2024-12  Clothing        825\n",
      "\n",
      "City 9:\n",
      "          date  category  net_units\n",
      "19    2022-01  Clothing        529\n",
      "69    2022-02  Clothing        477\n",
      "119   2022-03  Clothing        594\n",
      "169   2022-04  Clothing        634\n",
      "219   2022-05  Clothing        527\n",
      "269   2022-06  Clothing        569\n",
      "319   2022-07  Clothing        558\n",
      "389   2022-08      Home        509\n",
      "419   2022-09  Clothing        561\n",
      "469   2022-10  Clothing        566\n",
      "519   2022-11  Clothing        794\n",
      "569   2022-12  Clothing        893\n",
      "619   2023-01  Clothing        647\n",
      "669   2023-02  Clothing        524\n",
      "719   2023-03  Clothing        604\n",
      "769   2023-04  Clothing        583\n",
      "819   2023-05  Clothing        593\n",
      "869   2023-06  Clothing        529\n",
      "939   2023-07      Home        501\n",
      "969   2023-08  Clothing        569\n",
      "1019  2023-09  Clothing        506\n",
      "1069  2023-10  Clothing        606\n",
      "1119  2023-11  Clothing        801\n",
      "1169  2023-12  Clothing        820\n",
      "1219  2024-01  Clothing        599\n",
      "1269  2024-02  Clothing        569\n",
      "1319  2024-03  Clothing        613\n",
      "1369  2024-04  Clothing        533\n",
      "1419  2024-05  Clothing        608\n",
      "1469  2024-06  Clothing        529\n",
      "1519  2024-07  Clothing        575\n",
      "1569  2024-08  Clothing        529\n",
      "1619  2024-09  Clothing        569\n",
      "1669  2024-10  Clothing        532\n",
      "1719  2024-11  Clothing        701\n",
      "1769  2024-12  Clothing        729\n",
      "\n",
      "City 10:\n",
      "          date  category  net_units\n",
      "11    2022-01  Clothing        697\n",
      "61    2022-02  Clothing        592\n",
      "111   2022-03  Clothing        583\n",
      "161   2022-04  Clothing        668\n",
      "211   2022-05  Clothing        652\n",
      "261   2022-06  Clothing        553\n",
      "311   2022-07  Clothing        593\n",
      "361   2022-08  Clothing        563\n",
      "411   2022-09  Clothing        682\n",
      "461   2022-10  Clothing        622\n",
      "511   2022-11  Clothing        784\n",
      "561   2022-12  Clothing        795\n",
      "631   2023-01      Home        636\n",
      "661   2023-02  Clothing        497\n",
      "711   2023-03  Clothing        642\n",
      "761   2023-04  Clothing        669\n",
      "811   2023-05  Clothing        565\n",
      "861   2023-06  Clothing        584\n",
      "911   2023-07  Clothing        614\n",
      "961   2023-08  Clothing        565\n",
      "1011  2023-09  Clothing        610\n",
      "1061  2023-10  Clothing        598\n",
      "1111  2023-11  Clothing        746\n",
      "1161  2023-12  Clothing        794\n",
      "1211  2024-01  Clothing        638\n",
      "1261  2024-02  Clothing        501\n",
      "1311  2024-03  Clothing        623\n",
      "1361  2024-04  Clothing        631\n",
      "1411  2024-05  Clothing        601\n",
      "1461  2024-06  Clothing        625\n",
      "1531  2024-07      Home        513\n",
      "1561  2024-08  Clothing        627\n",
      "1611  2024-09  Clothing        615\n",
      "1661  2024-10  Clothing        617\n",
      "1711  2024-11  Clothing        827\n",
      "1761  2024-12  Clothing        884\n"
     ]
    }
   ],
   "source": [
    "df_6_1_series = df_6_1.loc[df_6_1.groupby(['date'])['net_units'].idxmax()]\n",
    "print('City 1:\\n',df_6_1_series)\n",
    "df_6_2_series = df_6_2.loc[df_6_2.groupby(['date'])['net_units'].idxmax()]\n",
    "print('\\nCity 2:\\n',df_6_2_series)\n",
    "df_6_3_series = df_6_3.loc[df_6_3.groupby(['date'])['net_units'].idxmax()]\n",
    "print('\\nCity 3:\\n',df_6_3_series)\n",
    "df_6_4_series = df_6_4.loc[df_6_4.groupby(['date'])['net_units'].idxmax()]\n",
    "print('\\nCity 4:\\n',df_6_4_series)\n",
    "df_6_5_series = df_6_5.loc[df_6_5.groupby(['date'])['net_units'].idxmax()]\n",
    "print('\\nCity 5:\\n',df_6_5_series)\n",
    "df_6_6_series = df_6_6.loc[df_6_6.groupby(['date'])['net_units'].idxmax()]\n",
    "print('\\nCity 6:\\n',df_6_6_series)\n",
    "df_6_7_series = df_6_7.loc[df_6_7.groupby(['date'])['net_units'].idxmax()]\n",
    "print('\\nCity 7:\\n',df_6_7_series)\n",
    "df_6_8_series = df_6_8.loc[df_6_8.groupby(['date'])['net_units'].idxmax()]\n",
    "print('\\nCity 8:\\n',df_6_8_series)\n",
    "df_6_9_series = df_6_9.loc[df_6_9.groupby(['date'])['net_units'].idxmax()]\n",
    "print('\\nCity 9:\\n',df_6_9_series)\n",
    "df_6_10_series = df_6_10.loc[df_6_10.groupby(['date'])['net_units'].idxmax()]\n",
    "print('\\nCity 10:\\n',df_6_10_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1684e4bc",
   "metadata": {},
   "source": [
    "To easen the pattern analyzation process, we can group by continuous segments with the same category as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b31fea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_group(df):\n",
    "    # Ensure the dates are sorted,\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "    # Add column to flag group and group data.\n",
    "    df['group'] = (df['category'] != df['category'].shift()).cumsum()\n",
    "    df_group = (\n",
    "        df.groupby(['group', 'category'])\n",
    "        .agg(\n",
    "            start_date=('date', 'first'),\n",
    "            end_date=('date', 'last'),\n",
    "            total_units=('net_units', 'sum')\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    df_group['date'] = df_group['start_date'] + ' - ' + df_group['end_date']\n",
    "    df_group = df_group[['date', 'category', 'total_units']]\n",
    "    return df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "4203199d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City 1:\n",
      "                 date  category  total_units\n",
      "0  2022-01 - 2023-10  Clothing        13692\n",
      "1  2023-11 - 2023-12      Home         1635\n",
      "2  2024-01 - 2024-07  Clothing         4166\n",
      "3  2024-08 - 2024-08      Home          557\n",
      "4  2024-09 - 2024-12  Clothing         2909\n",
      "City 2:\n",
      "                 date  category  total_units\n",
      "0  2022-01 - 2023-05  Clothing        11722\n",
      "1  2023-06 - 2023-06      Home          546\n",
      "2  2023-07 - 2023-08  Clothing         1194\n",
      "3  2023-09 - 2023-09      Home          660\n",
      "4  2023-10 - 2024-11  Clothing         9768\n",
      "5  2024-12 - 2024-12      Home          947\n",
      "City 3:\n",
      "                 date  category  total_units\n",
      "0  2022-01 - 2022-01      Home          556\n",
      "1  2022-02 - 2022-04  Clothing         1559\n",
      "2  2022-05 - 2022-06      Home         1018\n",
      "3  2022-07 - 2023-02  Clothing         4961\n",
      "4  2023-03 - 2023-03      Home          561\n",
      "5  2023-04 - 2023-11  Clothing         4745\n",
      "6  2023-12 - 2023-12      Home          788\n",
      "7  2024-01 - 2024-07  Clothing         4046\n",
      "8  2024-08 - 2024-08      Home          512\n",
      "9  2024-09 - 2024-12  Clothing         2642\n",
      "City 4:\n",
      "                 date  category  total_units\n",
      "0  2022-01 - 2022-06  Clothing         3652\n",
      "1  2022-07 - 2022-07      Home          595\n",
      "2  2022-08 - 2022-08  Clothing          614\n",
      "3  2022-09 - 2022-09      Home          526\n",
      "4  2022-10 - 2023-06  Clothing         6041\n",
      "5  2023-07 - 2023-07      Home          572\n",
      "6  2023-08 - 2024-06  Clothing         7285\n",
      "7  2024-07 - 2024-07      Home          579\n",
      "8  2024-08 - 2024-12  Clothing         3617\n",
      "City 5:\n",
      "                 date  category  total_units\n",
      "0  2022-01 - 2022-01  Clothing          700\n",
      "1  2022-02 - 2022-02      Home          510\n",
      "2  2022-03 - 2023-07  Clothing        11248\n",
      "3  2023-08 - 2023-08      Home          590\n",
      "4  2023-09 - 2024-05  Clothing         6195\n",
      "5  2024-06 - 2024-06      Home          615\n",
      "6  2024-07 - 2024-12  Clothing         4554\n",
      "City 6:\n",
      "                 date  category  total_units\n",
      "0  2022-01 - 2022-03      Home         1610\n",
      "1  2022-04 - 2022-06  Clothing         1757\n",
      "2  2022-07 - 2022-07      Home          551\n",
      "3  2022-08 - 2023-06  Clothing         7034\n",
      "4  2023-07 - 2023-07      Home          513\n",
      "5  2023-08 - 2024-07  Clothing         7289\n",
      "6  2024-08 - 2024-08      Home          546\n",
      "7  2024-09 - 2024-10  Clothing         1154\n",
      "8  2024-11 - 2024-12      Home         1570\n",
      "City 7:\n",
      "                  date  category  total_units\n",
      "0   2022-01 - 2022-05  Clothing         3048\n",
      "1   2022-06 - 2022-06      Home          473\n",
      "2   2022-07 - 2023-02  Clothing         5324\n",
      "3   2023-03 - 2023-03      Home          545\n",
      "4   2023-04 - 2023-08  Clothing         3004\n",
      "5   2023-09 - 2023-09      Home          600\n",
      "6   2023-10 - 2023-10  Clothing          595\n",
      "7   2023-11 - 2023-11      Home          812\n",
      "8   2023-12 - 2024-05  Clothing         3747\n",
      "9   2024-06 - 2024-06      Home          551\n",
      "10  2024-07 - 2024-10  Clothing         2497\n",
      "11  2024-11 - 2024-11      Home          839\n",
      "12  2024-12 - 2024-12  Clothing          894\n",
      "City 8:\n",
      "                  date  category  total_units\n",
      "0   2022-01 - 2022-03  Clothing         1948\n",
      "1   2022-04 - 2022-05      Home         1194\n",
      "2   2022-06 - 2023-01  Clothing         5763\n",
      "3   2023-02 - 2023-02      Home          619\n",
      "4   2023-03 - 2023-09  Clothing         4304\n",
      "5   2023-10 - 2023-10      Home          635\n",
      "6   2023-11 - 2024-02  Clothing         3088\n",
      "7   2024-03 - 2024-03      Home          627\n",
      "8   2024-04 - 2024-09  Clothing         3614\n",
      "9   2024-10 - 2024-10      Home          627\n",
      "10  2024-11 - 2024-12  Clothing         1709\n",
      "City 9:\n",
      "                 date  category  total_units\n",
      "0  2022-01 - 2022-07  Clothing         3888\n",
      "1  2022-08 - 2022-08      Home          509\n",
      "2  2022-09 - 2023-06  Clothing         6294\n",
      "3  2023-07 - 2023-07      Home          501\n",
      "4  2023-08 - 2024-12  Clothing        10388\n",
      "City 10:\n",
      "                 date  category  total_units\n",
      "0  2022-01 - 2022-12  Clothing         7784\n",
      "1  2023-01 - 2023-01      Home          636\n",
      "2  2023-02 - 2024-06  Clothing        10503\n",
      "3  2024-07 - 2024-07      Home          513\n",
      "4  2024-08 - 2024-12  Clothing         3570\n"
     ]
    }
   ],
   "source": [
    "df_6_1_series = series_group(df_6_1_series)\n",
    "print('City 1:\\n',df_6_1_series)\n",
    "df_6_2_series = series_group(df_6_2_series)\n",
    "print('City 2:\\n',df_6_2_series)\n",
    "df_6_3_series = series_group(df_6_3_series)\n",
    "print('City 3:\\n',df_6_3_series)\n",
    "df_6_4_series = series_group(df_6_4_series)\n",
    "print('City 4:\\n',df_6_4_series)\n",
    "df_6_5_series = series_group(df_6_5_series)\n",
    "print('City 5:\\n',df_6_5_series)\n",
    "df_6_6_series = series_group(df_6_6_series)\n",
    "print('City 6:\\n',df_6_6_series)\n",
    "df_6_7_series = series_group(df_6_7_series)\n",
    "print('City 7:\\n',df_6_7_series)\n",
    "df_6_8_series = series_group(df_6_8_series)\n",
    "print('City 8:\\n',df_6_8_series)\n",
    "df_6_9_series = series_group(df_6_9_series)\n",
    "print('City 9:\\n',df_6_9_series)\n",
    "df_6_10_series = series_group(df_6_10_series)\n",
    "print('City 10:\\n',df_6_10_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f030e98a",
   "metadata": {},
   "source": [
    "As shown above, each city varies in trend and interest over the months. However, the top product's category across those months and cities are always whether **Clothing** or **Home**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b44ec2b",
   "metadata": {},
   "source": [
    "## 7. How does discount percentages on products affect store's sales and revenue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7617ee09",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "d859fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id  discount_pct  net_units  net_revenue\n",
      "0   prod_031           0.0          7       303.32\n",
      "1   prod_041          30.0          5       432.56\n",
      "2   prod_022           0.0          2        22.09\n",
      "3   prod_037           0.0          1       284.06\n",
      "4   prod_018           0.0          2       113.16\n"
     ]
    }
   ],
   "source": [
    "# Each rows are proven unique by the previous step so we can exclude the `date` in this section.\n",
    "# Discount percentage applies to one specific product and the product is not always on discount.\n",
    "# Therefore, we need to include product ID data and analyze the effect for each product\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_7 = df[['product_id','discount_pct','net_units','net_revenue']].copy()\n",
    "print(df_7.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169751d",
   "metadata": {},
   "source": [
    "Separate data by product ID to support product-based analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f7b8968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data first for neat visuals.\n",
    "df_7 = df_7.sort_values('product_id').reset_index(drop=True)\n",
    "\n",
    "disc_dfs = {}\n",
    "\n",
    "for prod_id in df_7['product_id'].unique():\n",
    "    df_disc = df_7[df_7['product_id'] == prod_id].drop(columns='product_id')\n",
    "    disc_dfs[prod_id] = df_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e15c56ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod_031:\n",
      "        discount_pct  net_units  net_revenue\n",
      "98618           0.0          1        44.42\n",
      "98619           0.0          5       214.38\n",
      "98620           0.0          4       173.08\n",
      "98621           0.0         10       429.38\n",
      "98622           0.0          4       177.32\n",
      "prod_041:\n",
      "         discount_pct  net_units  net_revenue\n",
      "131632          30.0          4       344.74\n",
      "131633           0.0          3       364.89\n",
      "131634           0.0          3       366.98\n",
      "131635           0.0          2       247.80\n",
      "131636          15.0          3       314.60\n",
      "prod_022:\n",
      "        discount_pct  net_units  net_revenue\n",
      "68855           0.0          6        66.35\n",
      "68856           0.0          4        44.94\n",
      "68857           5.0          1        10.55\n",
      "68858           0.0          3        35.00\n",
      "68859           0.0          6        66.67\n"
     ]
    }
   ],
   "source": [
    "# Output examples.\n",
    "print('prod_031:\\n',disc_dfs['prod_031'].head())\n",
    "print('prod_041:\\n',disc_dfs['prod_041'].head())\n",
    "print('prod_022:\\n',disc_dfs['prod_022'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d16820",
   "metadata": {},
   "source": [
    "Find the correlation coefficients between `discount_pct`, `net_units`, and `net_revenue` for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "2ecac89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " prod_001 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.023069    -0.122153\n",
      "net_units         0.023069   1.000000     0.985899\n",
      "net_revenue      -0.122153   0.985899     1.000000\n",
      "\n",
      " prod_002 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.053468    -0.060733\n",
      "net_units         0.053468   1.000000     0.989991\n",
      "net_revenue      -0.060733   0.989991     1.000000\n",
      "\n",
      " prod_003 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.020858    -0.111075\n",
      "net_units         0.020858   1.000000     0.987651\n",
      "net_revenue      -0.111075   0.987651     1.000000\n",
      "\n",
      " prod_004 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct       1.00000   0.045510    -0.093370\n",
      "net_units          0.04551   1.000000     0.986788\n",
      "net_revenue       -0.09337   0.986788     1.000000\n",
      "\n",
      " prod_005 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.014563    -0.130000\n",
      "net_units         0.014563   1.000000     0.986114\n",
      "net_revenue      -0.130000   0.986114     1.000000\n",
      "\n",
      " prod_006 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.047881    -0.089490\n",
      "net_units         0.047881   1.000000     0.986934\n",
      "net_revenue      -0.089490   0.986934     1.000000\n",
      "\n",
      " prod_007 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.020116    -0.124053\n",
      "net_units         0.020116   1.000000     0.985903\n",
      "net_revenue      -0.124053   0.985903     1.000000\n",
      "\n",
      " prod_008 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.012317    -0.107605\n",
      "net_units         0.012317   1.000000     0.989582\n",
      "net_revenue      -0.107605   0.989582     1.000000\n",
      "\n",
      " prod_009 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.013095    -0.109701\n",
      "net_units         0.013095   1.000000     0.988962\n",
      "net_revenue      -0.109701   0.988962     1.000000\n",
      "\n",
      " prod_010 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.035078    -0.106064\n",
      "net_units         0.035078   1.000000     0.986021\n",
      "net_revenue      -0.106064   0.986021     1.000000\n",
      "\n",
      " prod_011 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.016637    -0.131202\n",
      "net_units         0.016637   1.000000     0.985155\n",
      "net_revenue      -0.131202   0.985155     1.000000\n",
      "\n",
      " prod_012 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.043672    -0.096125\n",
      "net_units         0.043672   1.000000     0.986562\n",
      "net_revenue      -0.096125   0.986562     1.000000\n",
      "\n",
      " prod_013 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.014195    -0.114220\n",
      "net_units         0.014195   1.000000     0.988579\n",
      "net_revenue      -0.114220   0.988579     1.000000\n",
      "\n",
      " prod_014 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.001774    -0.105711\n",
      "net_units         0.001774   1.000000     0.990971\n",
      "net_revenue      -0.105711   0.990971     1.000000\n",
      "\n",
      " prod_015 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.051081    -0.081228\n",
      "net_units         0.051081   1.000000     0.987699\n",
      "net_revenue      -0.081228   0.987699     1.000000\n",
      "\n",
      " prod_016 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.000954    -0.128086\n",
      "net_units         0.000954   1.000000     0.988110\n",
      "net_revenue      -0.128086   0.988110     1.000000\n",
      "\n",
      " prod_017 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.012232    -0.100481\n",
      "net_units         0.012232   1.000000     0.990047\n",
      "net_revenue      -0.100481   0.990047     1.000000\n",
      "\n",
      " prod_018 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.000178    -0.125196\n",
      "net_units         0.000178   1.000000     0.988175\n",
      "net_revenue      -0.125196   0.988175     1.000000\n",
      "\n",
      " prod_019 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.019449    -0.108568\n",
      "net_units         0.019449   1.000000     0.988321\n",
      "net_revenue      -0.108568   0.988321     1.000000\n",
      "\n",
      " prod_020 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.024130    -0.113098\n",
      "net_units         0.024130   1.000000     0.986861\n",
      "net_revenue      -0.113098   0.986861     1.000000\n",
      "\n",
      " prod_021 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   -0.00333    -0.132176\n",
      "net_units        -0.003330    1.00000     0.988420\n",
      "net_revenue      -0.132176    0.98842     1.000000\n",
      "\n",
      " prod_022 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.008804    -0.120881\n",
      "net_units         0.008804   1.000000     0.988153\n",
      "net_revenue      -0.120881   0.988153     1.000000\n",
      "\n",
      " prod_023 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.046286    -0.104843\n",
      "net_units         0.046286   1.000000     0.984678\n",
      "net_revenue      -0.104843   0.984678     1.000000\n",
      "\n",
      " prod_024 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.021287     -0.10196\n",
      "net_units         0.021287   1.000000      0.98856\n",
      "net_revenue      -0.101960   0.988560      1.00000\n",
      "\n",
      " prod_025 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.006572    -0.111500\n",
      "net_units         0.006572   1.000000     0.989658\n",
      "net_revenue      -0.111500   0.989658     1.000000\n",
      "\n",
      " prod_026 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000  -0.017004    -0.126532\n",
      "net_units        -0.017004   1.000000     0.990569\n",
      "net_revenue      -0.126532   0.990569     1.000000\n",
      "\n",
      " prod_027 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.008412    -0.105466\n",
      "net_units         0.008412   1.000000     0.990631\n",
      "net_revenue      -0.105466   0.990631     1.000000\n",
      "\n",
      " prod_028 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.034894    -0.103595\n",
      "net_units         0.034894   1.000000     0.986638\n",
      "net_revenue      -0.103595   0.986638     1.000000\n",
      "\n",
      " prod_029 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.016093    -0.113204\n",
      "net_units         0.016093   1.000000     0.988206\n",
      "net_revenue      -0.113204   0.988206     1.000000\n",
      "\n",
      " prod_030 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.060496    -0.084309\n",
      "net_units         0.060496   1.000000     0.985362\n",
      "net_revenue      -0.084309   0.985362     1.000000\n",
      "\n",
      " prod_031 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.025978    -0.105714\n",
      "net_units         0.025978   1.000000     0.987183\n",
      "net_revenue      -0.105714   0.987183     1.000000\n",
      "\n",
      " prod_032 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.034961    -0.082813\n",
      "net_units         0.034961   1.000000     0.989762\n",
      "net_revenue      -0.082813   0.989762     1.000000\n",
      "\n",
      " prod_033 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.037582    -0.093033\n",
      "net_units         0.037582   1.000000     0.987905\n",
      "net_revenue      -0.093033   0.987905     1.000000\n",
      "\n",
      " prod_034 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.024130    -0.124176\n",
      "net_units         0.024130   1.000000     0.985348\n",
      "net_revenue      -0.124176   0.985348     1.000000\n",
      "\n",
      " prod_035 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.033363    -0.104047\n",
      "net_units         0.033363   1.000000     0.986570\n",
      "net_revenue      -0.104047   0.986570     1.000000\n",
      "\n",
      " prod_036 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000  -0.023289    -0.144273\n",
      "net_units        -0.023289   1.000000     0.989624\n",
      "net_revenue      -0.144273   0.989624     1.000000\n",
      "\n",
      " prod_037 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.157197     0.009719\n",
      "net_units         0.157197   1.000000     0.984596\n",
      "net_revenue       0.009719   0.984596     1.000000\n",
      "\n",
      " prod_038 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.018079    -0.115755\n",
      "net_units         0.018079   1.000000     0.987175\n",
      "net_revenue      -0.115755   0.987175     1.000000\n",
      "\n",
      " prod_039 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.063848    -0.091730\n",
      "net_units         0.063848   1.000000     0.983849\n",
      "net_revenue      -0.091730   0.983849     1.000000\n",
      "\n",
      " prod_040 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.126851    -0.028338\n",
      "net_units         0.126851   1.000000     0.984168\n",
      "net_revenue      -0.028338   0.984168     1.000000\n",
      "\n",
      " prod_041 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.087665    -0.042749\n",
      "net_units         0.087665   1.000000     0.987647\n",
      "net_revenue      -0.042749   0.987647     1.000000\n",
      "\n",
      " prod_042 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.030299    -0.094962\n",
      "net_units         0.030299   1.000000     0.988758\n",
      "net_revenue      -0.094962   0.988758     1.000000\n",
      "\n",
      " prod_043 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.042200    -0.089291\n",
      "net_units         0.042200   1.000000     0.987572\n",
      "net_revenue      -0.089291   0.987572     1.000000\n",
      "\n",
      " prod_044 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.005720    -0.126086\n",
      "net_units         0.005720   1.000000     0.987966\n",
      "net_revenue      -0.126086   0.987966     1.000000\n",
      "\n",
      " prod_045 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.048948    -0.091151\n",
      "net_units         0.048948   1.000000     0.986421\n",
      "net_revenue      -0.091151   0.986421     1.000000\n",
      "\n",
      " prod_046 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.014821    -0.115922\n",
      "net_units         0.014821   1.000000     0.988109\n",
      "net_revenue      -0.115922   0.988109     1.000000\n",
      "\n",
      " prod_047 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.048686    -0.101965\n",
      "net_units         0.048686   1.000000     0.984679\n",
      "net_revenue      -0.101965   0.984679     1.000000\n",
      "\n",
      " prod_048 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.035350    -0.103671\n",
      "net_units         0.035350   1.000000     0.987139\n",
      "net_revenue      -0.103671   0.987139     1.000000\n",
      "\n",
      " prod_049 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.015325    -0.113561\n",
      "net_units         0.015325   1.000000     0.988037\n",
      "net_revenue      -0.113561   0.988037     1.000000\n",
      "\n",
      " prod_050 :\n",
      "               discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.016530    -0.113822\n",
      "net_units         0.016530   1.000000     0.988064\n",
      "net_revenue      -0.113822   0.988064     1.000000\n"
     ]
    }
   ],
   "source": [
    "for prod_id, df_disc in disc_dfs.items():\n",
    "    df_disc = df_disc[['discount_pct', 'net_units', 'net_revenue']].corr()\n",
    "    print('\\n',prod_id,':\\n',df_disc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e0e3e9",
   "metadata": {},
   "source": [
    "As shown above, discount percentages slightly impact sales and revenue. The higher the discount percentages, the higher the sales is. However, it is inversely proportional to the revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650a0dba",
   "metadata": {},
   "source": [
    "## 8. How does product's promotion affect store's sales and revenue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c00949f",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "27c7a13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id  promotion  net_units  net_revenue\n",
      "0   prod_031          0          7       303.32\n",
      "1   prod_041          0          5       432.56\n",
      "2   prod_022          0          2        22.09\n",
      "3   prod_037          0          1       284.06\n",
      "4   prod_018          0          2       113.16\n"
     ]
    }
   ],
   "source": [
    "# Each rows are proven unique by the previous step so we can exclude the `date` in this section.\n",
    "# Promotion applies to one specific product and the product is not always on promotion.\n",
    "# Therefore, we need to include product ID data and analyze the effect for each product\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_8 = df[['product_id','promotion','net_units','net_revenue']].copy()\n",
    "print(df_8.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c962f7",
   "metadata": {},
   "source": [
    "Separate data by product ID to support product-based analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "b1a56307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data first for neat visuals.\n",
    "df_8 = df_8.sort_values('product_id').reset_index(drop=True)\n",
    "\n",
    "promo_dfs = {}\n",
    "\n",
    "for prod_id in df_8['product_id'].unique():\n",
    "    df_promo = df_8[df_8['product_id'] == prod_id].drop(columns='product_id')\n",
    "    promo_dfs[prod_id] = df_promo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "1c3c72ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod_031:\n",
      "        promotion  net_units  net_revenue\n",
      "98618          0          1        44.42\n",
      "98619          0          5       214.38\n",
      "98620          0          4       173.08\n",
      "98621          1         10       429.38\n",
      "98622          0          4       177.32\n",
      "prod_041:\n",
      "         promotion  net_units  net_revenue\n",
      "131632          0          4       344.74\n",
      "131633          0          3       364.89\n",
      "131634          0          3       366.98\n",
      "131635          0          2       247.80\n",
      "131636          0          3       314.60\n",
      "prod_022:\n",
      "        promotion  net_units  net_revenue\n",
      "68855          0          6        66.35\n",
      "68856          0          4        44.94\n",
      "68857          0          1        10.55\n",
      "68858          0          3        35.00\n",
      "68859          0          6        66.67\n"
     ]
    }
   ],
   "source": [
    "# Output examples.\n",
    "print('prod_031:\\n',promo_dfs['prod_031'].head())\n",
    "print('prod_041:\\n',promo_dfs['prod_041'].head())\n",
    "print('prod_022:\\n',promo_dfs['prod_022'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b829b",
   "metadata": {},
   "source": [
    "Find the correlation coefficients between `promotion`, `net_units`, and `net_revenue` for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "dd9f72d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod_001 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.335476     0.328968\n",
      "net_units     0.335476   1.000000     0.985899\n",
      "net_revenue   0.328968   0.985899     1.000000\n",
      "prod_002 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.302539     0.296924\n",
      "net_units     0.302539   1.000000     0.989991\n",
      "net_revenue   0.296924   0.989991     1.000000\n",
      "prod_003 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.270640     0.263367\n",
      "net_units     0.270640   1.000000     0.987651\n",
      "net_revenue   0.263367   0.987651     1.000000\n",
      "prod_004 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.284677     0.288223\n",
      "net_units     0.284677   1.000000     0.986788\n",
      "net_revenue   0.288223   0.986788     1.000000\n",
      "prod_005 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.294855     0.290646\n",
      "net_units     0.294855   1.000000     0.986114\n",
      "net_revenue   0.290646   0.986114     1.000000\n",
      "prod_006 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.315588     0.315199\n",
      "net_units     0.315588   1.000000     0.986934\n",
      "net_revenue   0.315199   0.986934     1.000000\n",
      "prod_007 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.331457     0.320982\n",
      "net_units     0.331457   1.000000     0.985903\n",
      "net_revenue   0.320982   0.985903     1.000000\n",
      "prod_008 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.317912     0.316168\n",
      "net_units     0.317912   1.000000     0.989582\n",
      "net_revenue   0.316168   0.989582     1.000000\n",
      "prod_009 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.319652     0.319088\n",
      "net_units     0.319652   1.000000     0.988962\n",
      "net_revenue   0.319088   0.988962     1.000000\n",
      "prod_010 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.269573     0.263654\n",
      "net_units     0.269573   1.000000     0.986021\n",
      "net_revenue   0.263654   0.986021     1.000000\n",
      "prod_011 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.349205     0.343100\n",
      "net_units     0.349205   1.000000     0.985155\n",
      "net_revenue   0.343100   0.985155     1.000000\n",
      "prod_012 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.338839     0.341751\n",
      "net_units     0.338839   1.000000     0.986562\n",
      "net_revenue   0.341751   0.986562     1.000000\n",
      "prod_013 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.301914     0.298427\n",
      "net_units     0.301914   1.000000     0.988579\n",
      "net_revenue   0.298427   0.988579     1.000000\n",
      "prod_014 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.245267     0.243292\n",
      "net_units     0.245267   1.000000     0.990971\n",
      "net_revenue   0.243292   0.990971     1.000000\n",
      "prod_015 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.287541     0.288461\n",
      "net_units     0.287541   1.000000     0.987699\n",
      "net_revenue   0.288461   0.987699     1.000000\n",
      "prod_016 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.265897     0.265744\n",
      "net_units     0.265897   1.000000     0.988110\n",
      "net_revenue   0.265744   0.988110     1.000000\n",
      "prod_017 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.231409     0.234023\n",
      "net_units     0.231409   1.000000     0.990047\n",
      "net_revenue   0.234023   0.990047     1.000000\n",
      "prod_018 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.315819     0.317619\n",
      "net_units     0.315819   1.000000     0.988175\n",
      "net_revenue   0.317619   0.988175     1.000000\n",
      "prod_019 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.276157     0.270955\n",
      "net_units     0.276157   1.000000     0.988321\n",
      "net_revenue   0.270955   0.988321     1.000000\n",
      "prod_020 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.308653     0.307423\n",
      "net_units     0.308653   1.000000     0.986861\n",
      "net_revenue   0.307423   0.986861     1.000000\n",
      "prod_021 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000    0.33447     0.327117\n",
      "net_units     0.334470    1.00000     0.988420\n",
      "net_revenue   0.327117    0.98842     1.000000\n",
      "prod_022 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.279667     0.279795\n",
      "net_units     0.279667   1.000000     0.988153\n",
      "net_revenue   0.279795   0.988153     1.000000\n",
      "prod_023 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.360232     0.354834\n",
      "net_units     0.360232   1.000000     0.984678\n",
      "net_revenue   0.354834   0.984678     1.000000\n",
      "prod_024 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.280624     0.275136\n",
      "net_units     0.280624   1.000000     0.988560\n",
      "net_revenue   0.275136   0.988560     1.000000\n",
      "prod_025 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.336101     0.333944\n",
      "net_units     0.336101   1.000000     0.989658\n",
      "net_revenue   0.333944   0.989658     1.000000\n",
      "prod_026 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.304354     0.305727\n",
      "net_units     0.304354   1.000000     0.990569\n",
      "net_revenue   0.305727   0.990569     1.000000\n",
      "prod_027 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.281696     0.283476\n",
      "net_units     0.281696   1.000000     0.990631\n",
      "net_revenue   0.283476   0.990631     1.000000\n",
      "prod_028 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.305498     0.297471\n",
      "net_units     0.305498   1.000000     0.986638\n",
      "net_revenue   0.297471   0.986638     1.000000\n",
      "prod_029 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.307524     0.305716\n",
      "net_units     0.307524   1.000000     0.988206\n",
      "net_revenue   0.305716   0.988206     1.000000\n",
      "prod_030 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.298463     0.298179\n",
      "net_units     0.298463   1.000000     0.985362\n",
      "net_revenue   0.298179   0.985362     1.000000\n",
      "prod_031 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.292059     0.286742\n",
      "net_units     0.292059   1.000000     0.987183\n",
      "net_revenue   0.286742   0.987183     1.000000\n",
      "prod_032 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.289499     0.286230\n",
      "net_units     0.289499   1.000000     0.989762\n",
      "net_revenue   0.286230   0.989762     1.000000\n",
      "prod_033 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.286138     0.284955\n",
      "net_units     0.286138   1.000000     0.987905\n",
      "net_revenue   0.284955   0.987905     1.000000\n",
      "prod_034 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.357533     0.346581\n",
      "net_units     0.357533   1.000000     0.985348\n",
      "net_revenue   0.346581   0.985348     1.000000\n",
      "prod_035 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.325484     0.325724\n",
      "net_units     0.325484   1.000000     0.986570\n",
      "net_revenue   0.325724   0.986570     1.000000\n",
      "prod_036 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.318343     0.316933\n",
      "net_units     0.318343   1.000000     0.989624\n",
      "net_revenue   0.316933   0.989624     1.000000\n",
      "prod_037 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.294536     0.301142\n",
      "net_units     0.294536   1.000000     0.984596\n",
      "net_revenue   0.301142   0.984596     1.000000\n",
      "prod_038 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.305451     0.301603\n",
      "net_units     0.305451   1.000000     0.987175\n",
      "net_revenue   0.301603   0.987175     1.000000\n",
      "prod_039 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.367965     0.360309\n",
      "net_units     0.367965   1.000000     0.983849\n",
      "net_revenue   0.360309   0.983849     1.000000\n",
      "prod_040 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.316389     0.315303\n",
      "net_units     0.316389   1.000000     0.984168\n",
      "net_revenue   0.315303   0.984168     1.000000\n",
      "prod_041 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.265211     0.266676\n",
      "net_units     0.265211   1.000000     0.987647\n",
      "net_revenue   0.266676   0.987647     1.000000\n",
      "prod_042 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.284649     0.287670\n",
      "net_units     0.284649   1.000000     0.988758\n",
      "net_revenue   0.287670   0.988758     1.000000\n",
      "prod_043 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.287097     0.289284\n",
      "net_units     0.287097   1.000000     0.987572\n",
      "net_revenue   0.289284   0.987572     1.000000\n",
      "prod_044 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.318678     0.308332\n",
      "net_units     0.318678   1.000000     0.987966\n",
      "net_revenue   0.308332   0.987966     1.000000\n",
      "prod_045 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.332791     0.334214\n",
      "net_units     0.332791   1.000000     0.986421\n",
      "net_revenue   0.334214   0.986421     1.000000\n",
      "prod_046 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.274069     0.278730\n",
      "net_units     0.274069   1.000000     0.988109\n",
      "net_revenue   0.278730   0.988109     1.000000\n",
      "prod_047 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.334225     0.332234\n",
      "net_units     0.334225   1.000000     0.984679\n",
      "net_revenue   0.332234   0.984679     1.000000\n",
      "prod_048 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.293291     0.294989\n",
      "net_units     0.293291   1.000000     0.987139\n",
      "net_revenue   0.294989   0.987139     1.000000\n",
      "prod_049 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.316664     0.317557\n",
      "net_units     0.316664   1.000000     0.988037\n",
      "net_revenue   0.317557   0.988037     1.000000\n",
      "prod_050 :\n",
      "              promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.304591     0.307991\n",
      "net_units     0.304591   1.000000     0.988064\n",
      "net_revenue   0.307991   0.988064     1.000000\n"
     ]
    }
   ],
   "source": [
    "for prod_id, df_promo in promo_dfs.items():\n",
    "    df_promo = df_promo[['promotion', 'net_units', 'net_revenue']].corr()\n",
    "    print(prod_id,':\\n',df_promo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84aa046",
   "metadata": {},
   "source": [
    "As shown above, promotion slightly affects sales and revenue. However, the impact tends to be greater than the impact of discount percentages. Moreover, promotion has directly proportional relations with both sales and revenue. The presence of promotion triggers higher sales and revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868c75ed",
   "metadata": {},
   "source": [
    "## 9. Does the combination of discount and promotion gives different effect to store's sales and revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39f5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
