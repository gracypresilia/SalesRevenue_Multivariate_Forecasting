{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8165e61",
   "metadata": {},
   "source": [
    "# Import all packages/library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "db421e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helper' from 'c:\\\\Grace\\\\work\\\\`Apply\\\\CV_Portfolio\\\\Github\\\\3_Sales_Data_Forecasting\\\\helper.py'>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import helper\n",
    "importlib.reload(helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "79fccb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1750354",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7facd4",
   "metadata": {},
   "source": [
    "Read the raw data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "89b33990",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('./data/retail_sales_synthetic.csv')\n",
    "df = raw_df.copy()  # Copy to ensure every change made in this code doesn't affect the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f5487e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will be truncated if we printed it as df.head() or df.describe() so we can't check (see) all columns.\n",
    "# In order to avoid that, we need to print it partially.\n",
    "n_col = len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "090e8d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Dataframe Head:\n",
      "         date  store_id store_type region    city  store_area_sqft product_id  \\\n",
      "0  2024-09-05  store_09          C   East  city_9             2287   prod_031   \n",
      "1  2022-10-24  store_02          C   East  city_2             2627   prod_041   \n",
      "2  2023-04-19  store_06          B   West  city_6             2547   prod_022   \n",
      "3  2024-06-22  store_06          B   West  city_6             2547   prod_037   \n",
      "4  2024-07-20  store_02          C   East  city_2             2627   prod_018   \n",
      "\n",
      "   category  base_price  final_price  discount_pct  \n",
      "0      Home       43.01        43.33           0.0  \n",
      "1    Sports      121.31        86.51          30.0  \n",
      "2  Clothing       11.10        11.05           0.0  \n",
      "3    Beauty      272.28       284.06           0.0  \n",
      "4      Home       56.11        56.58           0.0  \n",
      "   promotion  is_holiday  day_of_week  weekend  units_sold  returns  \\\n",
      "0          0           0            3        0           8        1   \n",
      "1          0           1            0        0           5        0   \n",
      "2          0           0            2        0           2        0   \n",
      "3          0           0            5        1           2        1   \n",
      "4          0           0            5        1           2        0   \n",
      "\n",
      "   net_units  revenue  net_revenue  avg_rating  online  \n",
      "0          7   346.65       303.32        3.41       1  \n",
      "1          5   432.56       432.56        3.59       0  \n",
      "2          2    22.09        22.09        3.86       0  \n",
      "3          1   568.12       284.06        4.71       0  \n",
      "4          2   113.16       113.16        3.86       0  \n"
     ]
    }
   ],
   "source": [
    "print('\\nInitial Dataframe Head:')\n",
    "print(df.head().iloc[:, :int(n_col/2)])\n",
    "print(df.head().iloc[:, int(n_col/2):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "6096c8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Dataframe Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 164400 entries, 0 to 164399\n",
      "Data columns (total 22 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   date             164400 non-null  object \n",
      " 1   store_id         164400 non-null  object \n",
      " 2   store_type       164400 non-null  object \n",
      " 3   region           164400 non-null  object \n",
      " 4   city             164400 non-null  object \n",
      " 5   store_area_sqft  164400 non-null  int64  \n",
      " 6   product_id       164400 non-null  object \n",
      " 7   category         164400 non-null  object \n",
      " 8   base_price       164400 non-null  float64\n",
      " 9   final_price      164400 non-null  float64\n",
      " 10  discount_pct     164400 non-null  float64\n",
      " 11  promotion        164400 non-null  int64  \n",
      " 12  is_holiday       164400 non-null  int64  \n",
      " 13  day_of_week      164400 non-null  int64  \n",
      " 14  weekend          164400 non-null  int64  \n",
      " 15  units_sold       164400 non-null  int64  \n",
      " 16  returns          164400 non-null  int64  \n",
      " 17  net_units        164400 non-null  int64  \n",
      " 18  revenue          164400 non-null  float64\n",
      " 19  net_revenue      164400 non-null  float64\n",
      " 20  avg_rating       164400 non-null  float64\n",
      " 21  online           164400 non-null  int64  \n",
      "dtypes: float64(6), int64(9), object(7)\n",
      "memory usage: 27.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check the raw data information before preprocessing.\n",
    "print('\\nInitial Dataframe Information:')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "0ec76ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial Dataframe Numeric Stats:\n",
      "       store_area_sqft     base_price    final_price   discount_pct  \\\n",
      "count    164400.000000  164400.000000  164400.000000  164400.000000   \n",
      "mean       2440.700000      48.682199      46.781269       3.884519   \n",
      "std         317.638196      49.139032      47.473471       7.073051   \n",
      "min        1734.000000       5.800000       3.860000       0.000000   \n",
      "25%        2287.000000      17.750000      16.880000       0.000000   \n",
      "50%        2570.000000      31.030000      31.100000       0.000000   \n",
      "75%        2611.000000      59.100000      56.670000       5.000000   \n",
      "max        2904.000000     272.280000     293.690000      30.000000   \n",
      "\n",
      "           promotion     is_holiday    day_of_week  \n",
      "count  164400.000000  164400.000000  164400.000000  \n",
      "mean        0.079453       0.013686       3.000000  \n",
      "std         0.270445       0.116185       2.002286  \n",
      "min         0.000000       0.000000       0.000000  \n",
      "25%         0.000000       0.000000       1.000000  \n",
      "50%         0.000000       0.000000       3.000000  \n",
      "75%         0.000000       0.000000       5.000000  \n",
      "max         1.000000       1.000000       6.000000  \n",
      "             weekend     units_sold        returns      net_units  \\\n",
      "count  164400.000000  164400.000000  164400.000000  164400.000000   \n",
      "mean        0.286496       4.173650       0.083680       4.089970   \n",
      "std         0.452125       2.459849       0.290124       2.428308   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         0.000000       2.000000       0.000000       2.000000   \n",
      "50%         0.000000       4.000000       0.000000       4.000000   \n",
      "75%         1.000000       6.000000       0.000000       5.000000   \n",
      "max         1.000000      27.000000       3.000000      27.000000   \n",
      "\n",
      "             revenue    net_revenue     avg_rating         online  \n",
      "count  164400.000000  164400.000000  164400.000000  164400.000000  \n",
      "mean      192.050357     188.190366       3.968690       0.249957  \n",
      "std       242.874412     238.727862       0.400809       0.432989  \n",
      "min         0.000000       0.000000       1.980000       0.000000  \n",
      "25%        54.060000      52.930000       3.700000       0.000000  \n",
      "50%       114.270000     112.020000       3.970000       0.000000  \n",
      "75%       233.120000     228.262500       4.240000       0.000000  \n",
      "max      3765.810000    3466.290000       5.000000       1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Check the current data numeric stats before preprocessing.\n",
    "print('\\nInitial Dataframe Numeric Stats:')\n",
    "print(df.describe().iloc[:, :int(n_col/3)])\n",
    "print(df.describe().iloc[:, int(n_col/3):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37499c4a",
   "metadata": {},
   "source": [
    "As shown above, the data is already clean and ready to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fecc1c",
   "metadata": {},
   "source": [
    "# EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b161bb51",
   "metadata": {},
   "source": [
    "## 1. Does the presence of holiday affect overall sales and revenue, both daily and monthly?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb0efed",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107fda33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  is_holiday  net_units  net_revenue\n",
      "0  2024-09-05           0          7       303.32\n",
      "1  2022-10-24           1          5       432.56\n",
      "2  2023-04-19           0          2        22.09\n",
      "3  2024-06-22           0          1       284.06\n",
      "4  2024-07-20           0          2       113.16\n"
     ]
    }
   ],
   "source": [
    "# Each row is confirmed unique from the previous step so we can exclude the ID columns in this section.\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_1 = df[['date','is_holiday','net_units','net_revenue']].copy()\n",
    "print(df_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6558c448",
   "metadata": {},
   "source": [
    "### Holiday Effect Towards Daily Sales and Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42d468",
   "metadata": {},
   "source": [
    "Sum sales (units) and revenue of all stores and products each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95a4434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            is_holiday  net_units  net_revenue\n",
      "date                                          \n",
      "2022-01-01           0        633     32625.87\n",
      "2022-01-02           0        636     31625.80\n",
      "2022-01-03           0        574     30254.72\n",
      "2022-01-04           0        532     26296.65\n",
      "2022-01-05           0        568     25624.26\n"
     ]
    }
   ],
   "source": [
    "df_1 = df_1.groupby(df_1['date']).sum()\n",
    "# The line above sums all numeric data except `date` so `is_holiday` were also summed.\n",
    "# However, `is_holiday` is conditional data and is better represented as binary (0 or 1) in a day-by-day data.\n",
    "df_1.loc[df_1['is_holiday'] > 0, 'is_holiday'] = 1\n",
    "print(df_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa2ce65",
   "metadata": {},
   "source": [
    "Find the correlation coefficients between variables (`is_holiday`, `net_units`, and `net_revenue`) to analyze the effect of holiday to daily sales and revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0fb4dabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             is_holiday  net_units  net_revenue\n",
      "is_holiday     1.000000   0.169136     0.141445\n",
      "net_units      0.169136   1.000000     0.919873\n",
      "net_revenue    0.141445   0.919873     1.000000\n"
     ]
    }
   ],
   "source": [
    "corr_1_1 = df_1[['is_holiday', 'net_units', 'net_revenue']].corr()\n",
    "print(corr_1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3a27c3",
   "metadata": {},
   "source": [
    "Based on the results, the presence of holiday doesn't significantly affect the overall daily sales and revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c37493",
   "metadata": {},
   "source": [
    "### Holiday Effect Towards Monthly Sales and Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d40dde",
   "metadata": {},
   "source": [
    "Every dates in the current data are already unique so we can erase the day in the `date` data to support monthly-based analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "064a4ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         is_holiday  net_units  net_revenue\n",
      "date                                       \n",
      "2022-01           0        633     32625.87\n",
      "2022-01           0        636     31625.80\n",
      "2022-01           0        574     30254.72\n",
      "2022-01           0        532     26296.65\n",
      "2022-01           0        568     25624.26\n"
     ]
    }
   ],
   "source": [
    "df_1.index = dtm(df_1.index)\n",
    "print(df_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba6c05",
   "metadata": {},
   "source": [
    "Group (sum) the numeric data based on `date` to earn monthly net sales and revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "549a87db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         is_holiday  net_units  net_revenue\n",
      "date                                       \n",
      "2022-01           1      18498    860972.53\n",
      "2022-02           0      16240    743945.03\n",
      "2022-03           1      18163    833257.90\n",
      "2022-04           0      17575    830541.04\n",
      "2022-05           0      18032    811823.17\n"
     ]
    }
   ],
   "source": [
    "df_1 = df_1.groupby(df_1.index).sum()\n",
    "# In this section, `is_holiday` is no longer conditional and is expected to be summed as a representation for total holiday-days in a month.\n",
    "print(df_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d256a1a9",
   "metadata": {},
   "source": [
    "Find the correlation coefficients between variables (`is_holiday`, `net_units`, and `net_revenue`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "5ee86260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             is_holiday  net_units  net_revenue\n",
      "is_holiday     1.000000   0.218785     0.222019\n",
      "net_units      0.218785   1.000000     0.994426\n",
      "net_revenue    0.222019   0.994426     1.000000\n"
     ]
    }
   ],
   "source": [
    "corr_1_2 = df_1[['is_holiday', 'net_units', 'net_revenue']].corr()\n",
    "print(corr_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18134f6f",
   "metadata": {},
   "source": [
    "Based on the results, the presence of holiday doesn't significantly affect the overall monthly sales and revenue. However, the effect shows more than the daily analysis in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eb2267",
   "metadata": {},
   "source": [
    "## 2. Is there any change in product's category trend during no-holiday months and holiday months?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8053316",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d7e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  is_holiday  category  net_units\n",
      "0  2024-09-05           0      Home          7\n",
      "1  2022-10-24           1    Sports          5\n",
      "2  2023-04-19           0  Clothing          2\n",
      "3  2024-06-22           0    Beauty          1\n",
      "4  2024-07-20           0      Home          2\n"
     ]
    }
   ],
   "source": [
    "# Each row is confirmed unique from the previous step so we can exclude the ID columns in this section.\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_2 = df[['date','is_holiday','category','net_units']].copy()\n",
    "print(df_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fd12ce",
   "metadata": {},
   "source": [
    "Every dates in the current data are already uniquely paired with each category so we can erase the day in the `date` data to support monthly-based analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "82749c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date  is_holiday  category  net_units\n",
      "0  2024-09           0      Home          7\n",
      "1  2022-10           1    Sports          5\n",
      "2  2023-04           0  Clothing          2\n",
      "3  2024-06           0    Beauty          1\n",
      "4  2024-07           0      Home          2\n"
     ]
    }
   ],
   "source": [
    "df_2['date'] = dtm(df_2['date'])\n",
    "print(df_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87e5e44",
   "metadata": {},
   "source": [
    "Count `net_units` by month and product's category while keeping the `is_holiday` properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa407f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date     category  is_holiday  net_units\n",
      "0  2022-01       Beauty           1       1670\n",
      "1  2022-01     Clothing           1       6177\n",
      "2  2022-01  Electronics           1       3936\n",
      "3  2022-01         Home           1       5372\n",
      "4  2022-01       Sports           1       1343\n"
     ]
    }
   ],
   "source": [
    "df_2 = df_2.groupby(['date', 'category'], as_index=False)[['is_holiday','net_units']].sum()\n",
    "# The above line will sum `is_holiday` and `net_units` data based on unique pairs of `date` and `category`.\n",
    "# However, in this section, we need `is_holiday` as a conditional data so it is better represented as binary (0 or 1).\n",
    "df_2.loc[df_2['is_holiday'] > 0, 'is_holiday'] = 1\n",
    "print(df_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a5784",
   "metadata": {},
   "source": [
    "Only returns the highest sales product's category for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "624a4b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date  category  is_holiday  net_units\n",
      "1   2022-01  Clothing           1       6177\n",
      "6   2022-02  Clothing           0       5343\n",
      "11  2022-03  Clothing           1       6203\n",
      "16  2022-04  Clothing           0       6069\n",
      "21  2022-05  Clothing           0       6079\n"
     ]
    }
   ],
   "source": [
    "df_2 = df_2.loc[df_2.groupby('date')['net_units'].idxmax()]\n",
    "print(df_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00089934",
   "metadata": {},
   "source": [
    "Only returns the mode of the highest sales product's category across all of the no-holiday months and all of the holiday months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ec2e2dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_holiday\n",
      "0    Clothing\n",
      "1    Clothing\n",
      "Name: category, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_2 = df_2.groupby('is_holiday')['category'].agg(lambda x: x.mode()[0])\n",
    "print(df_2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f96643",
   "metadata": {},
   "source": [
    "As seen in the two latest dataframes, there's no change in product's category trend during no-holiday months and holiday months. Both product's category trends are clothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ccc942",
   "metadata": {},
   "source": [
    "## 3. Does the weekend status affect overall daily sales and revenue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df8fc63",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa42018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  weekend  net_units  net_revenue\n",
      "0  2024-09-05        0          7       303.32\n",
      "1  2022-10-24        0          5       432.56\n",
      "2  2023-04-19        0          2        22.09\n",
      "3  2024-06-22        1          1       284.06\n",
      "4  2024-07-20        1          2       113.16\n"
     ]
    }
   ],
   "source": [
    "# Each row is confirmed unique from the previous step so we can exclude the ID columns in this section.\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_3 = df[['date','weekend','net_units','net_revenue']].copy()\n",
    "print(df_3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a78aec",
   "metadata": {},
   "source": [
    "Sum sales (units) and revenue of all stores and products each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdfa0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            weekend  net_units  net_revenue\n",
      "date                                       \n",
      "2022-01-01        1        633     32625.87\n",
      "2022-01-02        1        636     31625.80\n",
      "2022-01-03        0        574     30254.72\n",
      "2022-01-04        0        532     26296.65\n",
      "2022-01-05        0        568     25624.26\n"
     ]
    }
   ],
   "source": [
    "df_3 = df_3.groupby(df_3['date']).sum()\n",
    "# The line above sums all numeric data except `date` so `weekend` were also summed.\n",
    "# However, `weekend` is conditional data and is better represented as binary (0 or 1) in a day-by-day data.\n",
    "df_3.loc[df_3['weekend'] > 0, 'weekend'] = 1\n",
    "print(df_3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3c25cf",
   "metadata": {},
   "source": [
    "Find the correlation coefficients between variables (`weekend`, `net_units`, and `net_revenue`) to analyze the effect of weekend to daily sales and revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8e281bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              weekend  net_units  net_revenue\n",
      "weekend      1.000000   0.511264     0.462136\n",
      "net_units    0.511264   1.000000     0.919873\n",
      "net_revenue  0.462136   0.919873     1.000000\n"
     ]
    }
   ],
   "source": [
    "corr_2 = df_3[['weekend', 'net_units', 'net_revenue']].corr()\n",
    "print(corr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fe7deb",
   "metadata": {},
   "source": [
    "Based on the results, the weekend status quite significantly affect the overall daily sales and revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa5abc",
   "metadata": {},
   "source": [
    "## 4. How is the overall day-by-day sales and revenue trend during a week?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df23e625",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a92d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   day_of_week  net_units  net_revenue\n",
      "0            3          7       303.32\n",
      "1            0          5       432.56\n",
      "2            2          2        22.09\n",
      "3            5          1       284.06\n",
      "4            5          2       113.16\n"
     ]
    }
   ],
   "source": [
    "# Each row is confirmed unique from the previous step so we can exclude the ID columns in this section.\n",
    "# Because this section analyze day or `day_of_week` instead of `date`, we can also exclide the `date` column.\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_4 = df[['day_of_week','net_units','net_revenue']].copy()\n",
    "print(df_4.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df807cf",
   "metadata": {},
   "source": [
    "Find the average values of sales and revenue for each day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "62e243ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             net_units  net_revenue\n",
      "day_of_week                        \n",
      "0             3.825563   177.054874\n",
      "1             3.819278   175.540487\n",
      "2             3.849615   176.279568\n",
      "3             3.831197   175.841911\n",
      "4             3.873120   178.832584\n",
      "5             4.691125   214.380471\n",
      "6             4.735329   219.188544\n"
     ]
    }
   ],
   "source": [
    "df_4 = df_4.groupby(df_4['day_of_week']).mean()\n",
    "print(df_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086986a5",
   "metadata": {},
   "source": [
    "The results show that sales and revenue are higher during weekends. This shows a consistent result between this section and previous section, the weekend status quite significantly affect the overall daily sales and revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934f99d",
   "metadata": {},
   "source": [
    "## 5. Does the store type and area affect the customer experience, which lead to store's sales and revenue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998dbd79",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b613be1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  store_type  store_area_sqft  avg_rating  net_units  net_revenue\n",
      "0          C             2287        3.41          7       303.32\n",
      "1          C             2627        3.59          5       432.56\n",
      "2          B             2547        3.86          2        22.09\n",
      "3          B             2547        4.71          1       284.06\n",
      "4          C             2627        3.86          2       113.16\n"
     ]
    }
   ],
   "source": [
    "# Each row is confirmed unique from the previous step so we can exclude the `date` and ID columns in this section.\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_5 = df[['store_type','store_area_sqft','avg_rating','net_units','net_revenue']].copy()\n",
    "print(df_5.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ea261",
   "metadata": {},
   "source": [
    "Find the average values of customer experiences, sales, and revenue for each store type and area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "73b5c3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  store_type  store_area_sqft  avg_rating  net_units  net_revenue\n",
      "0          A             1734    3.972809   4.283577   196.241209\n",
      "1          A             2593    3.964456   4.324088   200.346071\n",
      "2          A             2596    3.968857   4.059367   186.223064\n",
      "3          B             2547    3.965058   3.888564   175.711395\n",
      "4          C             2055    3.968860   4.095438   190.132041\n",
      "5          C             2287    3.968108   3.859124   178.184290\n",
      "6          C             2453    3.968673   4.051886   186.245386\n",
      "7          C             2611    3.970072   3.870073   177.580783\n",
      "8          C             2627    3.965832   4.363808   202.385544\n",
      "9          C             2904    3.974178   4.103771   188.853874\n"
     ]
    }
   ],
   "source": [
    "df_5 = df_5.groupby(['store_type', 'store_area_sqft'], as_index=False)[['avg_rating','net_units','net_revenue']].mean()\n",
    "print(df_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6df5ff6",
   "metadata": {},
   "source": [
    "### Store Type Effect Towards Average Customer Experiences, Sales, and Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8afab2",
   "metadata": {},
   "source": [
    "Find the average values of customer experiences, sales, and revenue for each store type only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "eb7d2183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            avg_rating  net_units  net_revenue\n",
      "store_type                                    \n",
      "A             3.968707   4.222344   194.270115\n",
      "B             3.965058   3.888564   175.711395\n",
      "C             3.969287   4.057350   187.230320\n"
     ]
    }
   ],
   "source": [
    "df_5_type = df_5.drop(columns='store_area_sqft').copy()\n",
    "df_5_type = df_5_type.groupby(df_5_type['store_type']).mean()\n",
    "print(df_5_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b5d8d4",
   "metadata": {},
   "source": [
    "The result above shows that store type, though it doesn't significantly affect customer experiences, quite significantly affect store's sales and revenue. Store type C has the highest rank, but store type A has the highest net sales and revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa874f76",
   "metadata": {},
   "source": [
    "### Store Area (in sqft) Effect Towards Average Customer Experiences, Sales, and Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d00088c",
   "metadata": {},
   "source": [
    "Find the correlation coefficients between `store_area_sqft`, `avg_rating`, `net_units`, and `net_revenue`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d769bba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 store_area_sqft  avg_rating  net_units  net_revenue\n",
      "store_area_sqft         1.000000   -0.174085  -0.132697    -0.125751\n",
      "avg_rating             -0.174085    1.000000  -0.065062    -0.070525\n",
      "net_units              -0.132697   -0.065062   1.000000     0.990896\n",
      "net_revenue            -0.125751   -0.070525   0.990896     1.000000\n"
     ]
    }
   ],
   "source": [
    "df_5_area = df_5[['store_area_sqft', 'avg_rating', 'net_units', 'net_revenue']].corr()\n",
    "print(df_5_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a32727",
   "metadata": {},
   "source": [
    "The result above shows that store area doesn't significantly affect either customer experiences, sales, nor revenue. Interestingly, larger store areas show a negative correlation with ratings, sales, and revenue suggesting that bigger spaces might not necessarily improve customer satisfaction. In addition, surprisingly, customer experiences also doesn't significantly affect either sales nor revenue and is on negative correlation, which means a higher rating results to lower sales and revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d59777",
   "metadata": {},
   "source": [
    "## 6. Which category of product is the most popular in each city month-by-month?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df60505",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f37d795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date    city  category  net_units\n",
      "0  2024-09-05  city_9      Home          7\n",
      "1  2022-10-24  city_2    Sports          5\n",
      "2  2023-04-19  city_6  Clothing          2\n",
      "3  2024-06-22  city_6    Beauty          1\n",
      "4  2024-07-20  city_2      Home          2\n"
     ]
    }
   ],
   "source": [
    "# Each row is confirmed unique from the previous step so we can exclude the `date` and ID columns in this section.\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_6 = df[['date','city','category','net_units']].copy()\n",
    "print(df_6.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1156fab1",
   "metadata": {},
   "source": [
    "Every dates in the current data are already uniquely paired with each category so we can erase the day in the `date` data to support monthly-based analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "1031f9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date    city  category  net_units\n",
      "0       2024-09  city_9      Home          7\n",
      "1       2022-10  city_2    Sports          5\n",
      "2       2023-04  city_6  Clothing          2\n",
      "3       2024-06  city_6    Beauty          1\n",
      "4       2024-07  city_2      Home          2\n",
      "...         ...     ...       ...        ...\n",
      "164395  2024-03  city_2    Sports          6\n",
      "164396  2023-11  city_3      Home          2\n",
      "164397  2024-05  city_6      Home          4\n",
      "164398  2024-09  city_2    Sports          1\n",
      "164399  2024-03  city_1    Beauty          5\n",
      "\n",
      "[164400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_6['date'] = dtm(df_6['date'])\n",
    "print(df_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145aa3f6",
   "metadata": {},
   "source": [
    "Count `net_units` by month and product's category while keeping the `city` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "483b5f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      date category     city  net_units\n",
      "0  2022-01   Beauty   city_1        176\n",
      "1  2022-01   Beauty  city_10        151\n",
      "2  2022-01   Beauty   city_2        150\n",
      "3  2022-01   Beauty   city_3        163\n",
      "4  2022-01   Beauty   city_4        181\n"
     ]
    }
   ],
   "source": [
    "df_6 = df_6.groupby(['date', 'category','city'], as_index=False)[['net_units']].sum()\n",
    "# The above line will sum `net_units` data based on unique pairs of `date`, `category`, and 'city'.\n",
    "print(df_6.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db81167",
   "metadata": {},
   "source": [
    "Separate data by city to support city-based analysis process and to ensure every store carries equal weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "fc98a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "city_dfs = {}\n",
    "separate(df_6, city_dfs, 'city')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c679b1",
   "metadata": {},
   "source": [
    "Returns the highest sales product's category for each pair of month and place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "24a1360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_1 :\n",
      "         date  category  net_units\n",
      "144  2022-01  Clothing        647\n",
      "122  2022-02  Clothing        579\n",
      "175  2022-03  Clothing        697\n",
      "40   2022-04  Clothing        625\n",
      "85   2022-05  Clothing        571\n",
      "city_10 :\n",
      "         date  category  net_units\n",
      "330  2022-01  Clothing        697\n",
      "314  2022-02  Clothing        592\n",
      "350  2022-03  Clothing        583\n",
      "339  2022-04  Clothing        668\n",
      "340  2022-05  Clothing        652\n",
      "city_2 :\n",
      "         date  category  net_units\n",
      "462  2022-01  Clothing        678\n",
      "430  2022-02  Clothing        566\n",
      "526  2022-03  Clothing        644\n",
      "417  2022-04  Clothing        670\n",
      "362  2022-05  Clothing        732\n",
      "city_3 :\n",
      "         date  category  net_units\n",
      "710  2022-01      Home        556\n",
      "572  2022-02  Clothing        459\n",
      "581  2022-03  Clothing        539\n",
      "550  2022-04  Clothing        561\n",
      "630  2022-05      Home        514\n",
      "city_4 :\n",
      "         date  category  net_units\n",
      "760  2022-01  Clothing        613\n",
      "731  2022-02  Clothing        523\n",
      "868  2022-03  Clothing        651\n",
      "892  2022-04  Clothing        604\n",
      "777  2022-05  Clothing        709\n",
      "city_5 :\n",
      "          date  category  net_units\n",
      "1060  2022-01  Clothing        700\n",
      "1058  2022-02      Home        510\n",
      "997   2022-03  Clothing        693\n",
      "1009  2022-04  Clothing        589\n",
      "982   2022-05  Clothing        640\n",
      "city_6 :\n",
      "          date  category  net_units\n",
      "1104  2022-01      Home        566\n",
      "1187  2022-02      Home        496\n",
      "1192  2022-03      Home        548\n",
      "1259  2022-04  Clothing        566\n",
      "1256  2022-05  Clothing        548\n",
      "city_7 :\n",
      "          date  category  net_units\n",
      "1321  2022-01  Clothing        609\n",
      "1324  2022-02  Clothing        537\n",
      "1278  2022-03  Clothing        659\n",
      "1325  2022-04  Clothing        630\n",
      "1301  2022-05  Clothing        613\n",
      "city_8 :\n",
      "          date  category  net_units\n",
      "1446  2022-01  Clothing        640\n",
      "1483  2022-02  Clothing        660\n",
      "1467  2022-03  Clothing        648\n",
      "1590  2022-04      Home        530\n",
      "1600  2022-05      Home        664\n",
      "city_9 :\n",
      "          date  category  net_units\n",
      "1693  2022-01  Clothing        529\n",
      "1688  2022-02  Clothing        477\n",
      "1683  2022-03  Clothing        594\n",
      "1686  2022-04  Clothing        634\n",
      "1714  2022-05  Clothing        527\n"
     ]
    }
   ],
   "source": [
    "for city, df_city in city_dfs.items():\n",
    "    df_city = df_city.loc[df_city.groupby(['date'])['net_units'].idxmax()]\n",
    "    city_dfs[city] = df_city\n",
    "    print(city,':\\n',df_city.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1684e4bc",
   "metadata": {},
   "source": [
    "To simplify the pattern analyzation process, we can group by continuous segments with the same category as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4203199d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_1 :\n",
      "                 date  category  total_item\n",
      "0  2022-01 - 2023-10  Clothing       13692\n",
      "1  2023-11 - 2023-12      Home        1635\n",
      "2  2024-01 - 2024-07  Clothing        4166\n",
      "3  2024-08 - 2024-08      Home         557\n",
      "4  2024-09 - 2024-12  Clothing        2909\n",
      "city_10 :\n",
      "                 date  category  total_item\n",
      "0  2022-01 - 2022-12  Clothing        7784\n",
      "1  2023-01 - 2023-01      Home         636\n",
      "2  2023-02 - 2024-06  Clothing       10503\n",
      "3  2024-07 - 2024-07      Home         513\n",
      "4  2024-08 - 2024-12  Clothing        3570\n",
      "city_2 :\n",
      "                 date  category  total_item\n",
      "0  2022-01 - 2023-05  Clothing       11722\n",
      "1  2023-06 - 2023-06      Home         546\n",
      "2  2023-07 - 2023-08  Clothing        1194\n",
      "3  2023-09 - 2023-09      Home         660\n",
      "4  2023-10 - 2024-11  Clothing        9768\n",
      "5  2024-12 - 2024-12      Home         947\n",
      "city_3 :\n",
      "                 date  category  total_item\n",
      "0  2022-01 - 2022-01      Home         556\n",
      "1  2022-02 - 2022-04  Clothing        1559\n",
      "2  2022-05 - 2022-06      Home        1018\n",
      "3  2022-07 - 2023-02  Clothing        4961\n",
      "4  2023-03 - 2023-03      Home         561\n",
      "5  2023-04 - 2023-11  Clothing        4745\n",
      "6  2023-12 - 2023-12      Home         788\n",
      "7  2024-01 - 2024-07  Clothing        4046\n",
      "8  2024-08 - 2024-08      Home         512\n",
      "9  2024-09 - 2024-12  Clothing        2642\n",
      "city_4 :\n",
      "                 date  category  total_item\n",
      "0  2022-01 - 2022-06  Clothing        3652\n",
      "1  2022-07 - 2022-07      Home         595\n",
      "2  2022-08 - 2022-08  Clothing         614\n",
      "3  2022-09 - 2022-09      Home         526\n",
      "4  2022-10 - 2023-06  Clothing        6041\n",
      "5  2023-07 - 2023-07      Home         572\n",
      "6  2023-08 - 2024-06  Clothing        7285\n",
      "7  2024-07 - 2024-07      Home         579\n",
      "8  2024-08 - 2024-12  Clothing        3617\n",
      "city_5 :\n",
      "                 date  category  total_item\n",
      "0  2022-01 - 2022-01  Clothing         700\n",
      "1  2022-02 - 2022-02      Home         510\n",
      "2  2022-03 - 2023-07  Clothing       11248\n",
      "3  2023-08 - 2023-08      Home         590\n",
      "4  2023-09 - 2024-05  Clothing        6195\n",
      "5  2024-06 - 2024-06      Home         615\n",
      "6  2024-07 - 2024-12  Clothing        4554\n",
      "city_6 :\n",
      "                 date  category  total_item\n",
      "0  2022-01 - 2022-03      Home        1610\n",
      "1  2022-04 - 2022-06  Clothing        1757\n",
      "2  2022-07 - 2022-07      Home         551\n",
      "3  2022-08 - 2023-06  Clothing        7034\n",
      "4  2023-07 - 2023-07      Home         513\n",
      "5  2023-08 - 2024-07  Clothing        7289\n",
      "6  2024-08 - 2024-08      Home         546\n",
      "7  2024-09 - 2024-10  Clothing        1154\n",
      "8  2024-11 - 2024-12      Home        1570\n",
      "city_7 :\n",
      "                  date  category  total_item\n",
      "0   2022-01 - 2022-05  Clothing        3048\n",
      "1   2022-06 - 2022-06      Home         473\n",
      "2   2022-07 - 2023-02  Clothing        5324\n",
      "3   2023-03 - 2023-03      Home         545\n",
      "4   2023-04 - 2023-08  Clothing        3004\n",
      "5   2023-09 - 2023-09      Home         600\n",
      "6   2023-10 - 2023-10  Clothing         595\n",
      "7   2023-11 - 2023-11      Home         812\n",
      "8   2023-12 - 2024-05  Clothing        3747\n",
      "9   2024-06 - 2024-06      Home         551\n",
      "10  2024-07 - 2024-10  Clothing        2497\n",
      "11  2024-11 - 2024-11      Home         839\n",
      "12  2024-12 - 2024-12  Clothing         894\n",
      "city_8 :\n",
      "                  date  category  total_item\n",
      "0   2022-01 - 2022-03  Clothing        1948\n",
      "1   2022-04 - 2022-05      Home        1194\n",
      "2   2022-06 - 2023-01  Clothing        5763\n",
      "3   2023-02 - 2023-02      Home         619\n",
      "4   2023-03 - 2023-09  Clothing        4304\n",
      "5   2023-10 - 2023-10      Home         635\n",
      "6   2023-11 - 2024-02  Clothing        3088\n",
      "7   2024-03 - 2024-03      Home         627\n",
      "8   2024-04 - 2024-09  Clothing        3614\n",
      "9   2024-10 - 2024-10      Home         627\n",
      "10  2024-11 - 2024-12  Clothing        1709\n",
      "city_9 :\n",
      "                 date  category  total_item\n",
      "0  2022-01 - 2022-07  Clothing        3888\n",
      "1  2022-08 - 2022-08      Home         509\n",
      "2  2022-09 - 2023-06  Clothing        6294\n",
      "3  2023-07 - 2023-07      Home         501\n",
      "4  2023-08 - 2024-12  Clothing       10388\n"
     ]
    }
   ],
   "source": [
    "for city, df_city in city_dfs.items():\n",
    "    # df_city = series_group(df_city)\n",
    "    df_city = series_group(df_city, 'category', 'net_units')\n",
    "    print(city,':\\n',df_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f030e98a",
   "metadata": {},
   "source": [
    "As shown above, each city displays different trends and preferences over time. However, the top product's category across those months and cities are always whether **Clothing** or **Home**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b44ec2b",
   "metadata": {},
   "source": [
    "## 7. How does discount percentages on products affect store's sales and revenue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7617ee09",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d859fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id  discount_pct  net_units  net_revenue\n",
      "0   prod_031           0.0          7       303.32\n",
      "1   prod_041          30.0          5       432.56\n",
      "2   prod_022           0.0          2        22.09\n",
      "3   prod_037           0.0          1       284.06\n",
      "4   prod_018           0.0          2       113.16\n"
     ]
    }
   ],
   "source": [
    "# Each row is confirmed unique from the previous step so we can exclude the `date` in this section.\n",
    "# Discount percentage applies to one specific product and the product is not always on discount.\n",
    "# Therefore, we need to include product ID data and analyze the effect for each product\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_7 = df[['product_id','discount_pct','net_units','net_revenue']].copy()\n",
    "print(df_7.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169751d",
   "metadata": {},
   "source": [
    "Separate data by product ID to support product-based analysis process and to ensure every product carries equal weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f7b8968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_dfs = {}\n",
    "separate(df_7, disc_dfs, 'product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e15c56ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod_031:\n",
      "        discount_pct  net_units  net_revenue\n",
      "98618           0.0          1        44.42\n",
      "98619           0.0          5       214.38\n",
      "98620           0.0          4       173.08\n",
      "98621           0.0         10       429.38\n",
      "98622           0.0          4       177.32\n",
      "prod_041:\n",
      "         discount_pct  net_units  net_revenue\n",
      "131632          30.0          4       344.74\n",
      "131633           0.0          3       364.89\n",
      "131634           0.0          3       366.98\n",
      "131635           0.0          2       247.80\n",
      "131636          15.0          3       314.60\n",
      "prod_022:\n",
      "        discount_pct  net_units  net_revenue\n",
      "68855           0.0          6        66.35\n",
      "68856           0.0          4        44.94\n",
      "68857           5.0          1        10.55\n",
      "68858           0.0          3        35.00\n",
      "68859           0.0          6        66.67\n"
     ]
    }
   ],
   "source": [
    "# Output examples.\n",
    "print('prod_031:\\n',disc_dfs['prod_031'].head())\n",
    "print('prod_041:\\n',disc_dfs['prod_041'].head())\n",
    "print('prod_022:\\n',disc_dfs['prod_022'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d16820",
   "metadata": {},
   "source": [
    "Find the correlation coefficients between `discount_pct`, `net_units`, and `net_revenue` for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2ecac89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prod_id, df_disc in disc_dfs.items():\n",
    "    df_disc = df_disc[['discount_pct', 'net_units', 'net_revenue']].corr()\n",
    "    disc_dfs[prod_id] = df_disc\n",
    "    # print('\\n',prod_id,':\\n',disc_dfs[prod_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340f63c",
   "metadata": {},
   "source": [
    "Average correlation values to find general insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6d324c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              discount_pct  net_units  net_revenue\n",
      "discount_pct      1.000000   0.029940    -0.102719\n",
      "net_units         0.029940   1.000000     0.987515\n",
      "net_revenue      -0.102719   0.987515     1.000000\n"
     ]
    }
   ],
   "source": [
    "disc_mat = []\n",
    "\n",
    "avg_disc_df = avg_corr(prod_id, df_disc, disc_dfs, disc_mat)\n",
    "print(avg_disc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e0e3e9",
   "metadata": {},
   "source": [
    "As shown above, discount percentages slightly impact sales and revenue. The higher the discount percentages, the higher the sales is. However, it is inversely proportional to the revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650a0dba",
   "metadata": {},
   "source": [
    "## 8. How does product's promotion affect store's sales and revenue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c00949f",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c7a13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id  promotion  net_units  net_revenue\n",
      "0   prod_031          0          7       303.32\n",
      "1   prod_041          0          5       432.56\n",
      "2   prod_022          0          2        22.09\n",
      "3   prod_037          0          1       284.06\n",
      "4   prod_018          0          2       113.16\n"
     ]
    }
   ],
   "source": [
    "# Each row is confirmed unique from the previous step so we can exclude the `date` in this section.\n",
    "# Promotion applies to one specific product and the product is not always on promotion.\n",
    "# Therefore, we need to include product ID data and analyze the effect for each product\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_8 = df[['product_id','promotion','net_units','net_revenue']].copy()\n",
    "print(df_8.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c962f7",
   "metadata": {},
   "source": [
    "Separate data by product ID to support product-based analysis process and to ensure every product carries equal weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b1a56307",
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_dfs = {}\n",
    "separate(df_8, promo_dfs, 'product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "1c3c72ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod_031:\n",
      "        promotion  net_units  net_revenue\n",
      "98618          0          1        44.42\n",
      "98619          0          5       214.38\n",
      "98620          0          4       173.08\n",
      "98621          1         10       429.38\n",
      "98622          0          4       177.32\n",
      "prod_041:\n",
      "         promotion  net_units  net_revenue\n",
      "131632          0          4       344.74\n",
      "131633          0          3       364.89\n",
      "131634          0          3       366.98\n",
      "131635          0          2       247.80\n",
      "131636          0          3       314.60\n",
      "prod_022:\n",
      "        promotion  net_units  net_revenue\n",
      "68855          0          6        66.35\n",
      "68856          0          4        44.94\n",
      "68857          0          1        10.55\n",
      "68858          0          3        35.00\n",
      "68859          0          6        66.67\n"
     ]
    }
   ],
   "source": [
    "# Output examples.\n",
    "print('prod_031:\\n',promo_dfs['prod_031'].head())\n",
    "print('prod_041:\\n',promo_dfs['prod_041'].head())\n",
    "print('prod_022:\\n',promo_dfs['prod_022'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b829b",
   "metadata": {},
   "source": [
    "Find the correlation coefficients between `promotion`, `net_units`, and `net_revenue` for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "dd9f72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prod_id, df_promo in promo_dfs.items():\n",
    "    df_promo = df_promo[['promotion', 'net_units', 'net_revenue']].corr()\n",
    "    promo_dfs[prod_id] = df_promo\n",
    "    # print(prod_id,':\\n',df_promo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c969a8",
   "metadata": {},
   "source": [
    "Average correlation values to find general insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1644a9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             promotion  net_units  net_revenue\n",
      "promotion     1.000000   0.304327     0.302372\n",
      "net_units     0.304327   1.000000     0.987515\n",
      "net_revenue   0.302372   0.987515     1.000000\n"
     ]
    }
   ],
   "source": [
    "promo_mat = []\n",
    "\n",
    "avg_promo_df = avg_corr(prod_id, df_promo, promo_dfs, promo_mat)\n",
    "print(avg_promo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84aa046",
   "metadata": {},
   "source": [
    "As shown above, promotion affects sales and revenue. The impact is far greater than the impact of discount percentages. Moreover, promotion has directly proportional relations with both sales and revenue. The presence of promotion triggers higher sales and revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868c75ed",
   "metadata": {},
   "source": [
    "## 9. How does the combination of discount and promotion give different effect to store's sales and revenue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5875dd62",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39f5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id  discount_pct  promotion  net_units  net_revenue\n",
      "0   prod_031           0.0          0          7       303.32\n",
      "1   prod_041          30.0          0          5       432.56\n",
      "2   prod_022           0.0          0          2        22.09\n",
      "3   prod_037           0.0          0          1       284.06\n",
      "4   prod_018           0.0          0          2       113.16\n"
     ]
    }
   ],
   "source": [
    "# Each row is confirmed unique from the previous step so we can exclude the `date` in this section.\n",
    "# Promotion applies to one specific product and the product is not always on promotion.\n",
    "# Therefore, we need to include product ID data and analyze the effect for each product\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_9 = df[['product_id','discount_pct','promotion','net_units','net_revenue']].copy()\n",
    "print(df_9.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f7314d",
   "metadata": {},
   "source": [
    "To analyze how the combination of discount and promotion gives different effect to store's sales and revenue, we need to pair each discount and promotion in categories.\n",
    "\n",
    "From the data preprocessing section, we already knew that the discount percentage value ranges from 0-30%. We will group these value into four categories: `no_disc`, `low_disc`, `mid_disc`, and `high_disc`. Meanwhile, the promotion value represents in a binary condition so there are only two categories: `no_promo` and `promo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7af52919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  product_id  discount_pct  promotion  net_units  net_revenue disc_group  \\\n",
      "0   prod_031           0.0          0          7       303.32    no_disc   \n",
      "1   prod_041          30.0          0          5       432.56  high_disc   \n",
      "2   prod_022           0.0          0          2        22.09    no_disc   \n",
      "3   prod_037           0.0          0          1       284.06    no_disc   \n",
      "4   prod_018           0.0          0          2       113.16    no_disc   \n",
      "\n",
      "  promo_group  \n",
      "0    no_promo  \n",
      "1    no_promo  \n",
      "2    no_promo  \n",
      "3    no_promo  \n",
      "4    no_promo  \n"
     ]
    }
   ],
   "source": [
    "df_9['disc_group'] = pd.cut(df_9['discount_pct'], bins=[-1, 0, 10, 20, 30], labels=['no_disc', 'low_disc', 'mid_disc', 'high_disc'])\n",
    "df_9['promo_group'] = df_9['promotion'].map({0: 'no_promo', 1: 'promo'})\n",
    "print(df_9.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77708a11",
   "metadata": {},
   "source": [
    "Separate data by product ID to support product-based analysis process and to ensure every product carries equal weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "82fed167",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_dfs = {}\n",
    "separate(df_9, comb_dfs, 'product_id')\n",
    "\n",
    "for prod_id, df_comb in comb_dfs.items():\n",
    "    df_comb = df_comb.drop(columns=['discount_pct','promotion'])\n",
    "    # We will do a cross group analysis process for each product, averaging values of sales and revenue for each combination of discount and promotion.\n",
    "    df_comb = df_comb.groupby(['disc_group', 'promo_group'], observed=True)[['net_units', 'net_revenue']].mean()\n",
    "    comb_dfs[prod_id] = df_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "0e2c73fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod_031:\n",
      "                         net_units  net_revenue\n",
      "disc_group promo_group                        \n",
      "no_disc    no_promo      3.617972   155.481581\n",
      "           promo         5.837563   250.939492\n",
      "low_disc   no_promo      3.478261   138.387022\n",
      "           promo         5.463415   218.210732\n",
      "mid_disc   no_promo      3.658470   129.864672\n",
      "           promo         6.742857   235.990286\n",
      "high_disc  no_promo      3.779661   114.377119\n",
      "           promo         6.750000   204.708750\n",
      "prod_041:\n",
      "                         net_units  net_revenue\n",
      "disc_group promo_group                        \n",
      "no_disc    no_promo      2.678134   324.856023\n",
      "           promo         4.502674   547.052620\n",
      "low_disc   no_promo      2.902597   325.389199\n",
      "           promo         5.000000   563.991778\n",
      "mid_disc   no_promo      3.042373   304.422119\n",
      "           promo         4.653846   469.412692\n",
      "high_disc  no_promo      3.412500   289.081125\n",
      "           promo         5.400000   455.961000\n",
      "prod_022:\n",
      "                         net_units  net_revenue\n",
      "disc_group promo_group                        \n",
      "no_disc    no_promo      4.058107    45.076284\n",
      "           promo         6.471910    71.856966\n",
      "low_disc   no_promo      4.028090    41.401629\n",
      "           promo         6.540000    67.323400\n",
      "mid_disc   no_promo      4.238606    38.869893\n",
      "           promo         7.952381    72.663810\n",
      "high_disc  no_promo      3.885246    30.262951\n",
      "           promo         4.500000    35.327500\n"
     ]
    }
   ],
   "source": [
    "# Output examples.\n",
    "print('prod_031:\\n',comb_dfs['prod_031'])\n",
    "print('prod_041:\\n',comb_dfs['prod_041'])\n",
    "print('prod_022:\\n',comb_dfs['prod_022'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c585068d",
   "metadata": {},
   "source": [
    "Average correlation values to find general insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2a38ded8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        net_units  net_revenue\n",
      "disc_group promo_group                        \n",
      "no_disc    no_promo      3.849325   183.086158\n",
      "           promo         6.482037   309.452271\n",
      "low_disc   no_promo      3.896958   175.041456\n",
      "           promo         6.449941   289.815817\n",
      "mid_disc   no_promo      4.009372   162.782706\n",
      "           promo         6.703554   270.579875\n",
      "high_disc  no_promo      4.184417   148.733762\n",
      "           promo         6.813056   249.538637\n"
     ]
    }
   ],
   "source": [
    "comb_mat = []\n",
    "\n",
    "avg_comb_df = cross_avg_mean(prod_id, df_comb, comb_dfs, comb_mat)\n",
    "print(avg_comb_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55389404",
   "metadata": {},
   "source": [
    "As shown above, combination of discount and promotion gives different effect to sales and revenue. High discount with promotion results in highest sales, but no discount with promotion results in highest revenue. This affirm the two previous sections' result that promotion has greater positive impact to sales and revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce140187",
   "metadata": {},
   "source": [
    "## 10. Does online transaction affect the customer experience (returns and rating)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dcbd53",
   "metadata": {},
   "source": [
    "Get the necessary columns from the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64de80c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store_id  online  returns  avg_rating\n",
      "0  store_09       1        1        3.41\n",
      "1  store_02       0        0        3.59\n",
      "2  store_06       0        0        3.86\n",
      "3  store_06       0        1        4.71\n",
      "4  store_02       0        0        3.86\n"
     ]
    }
   ],
   "source": [
    "# Each row is confirmed unique from the previous step so we can exclude the `date` in this section.\n",
    "# Customer experience varies between stores.\n",
    "# Therefore, we need to include store ID data to analyze online transaction effect to customer experience.\n",
    "# Copy to ensure every change made in this section doesn't affect the main data.\n",
    "df_10 = df[['store_id', 'online','returns','avg_rating']].copy()\n",
    "print(df_10.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5591630c",
   "metadata": {},
   "source": [
    "Separate data by store ID to support store-based analysis process and to ensure every store carries equal weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c4e7f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cx_dfs = {}\n",
    "separate(df_10, cx_dfs, 'store_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b688d7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_09:\n",
      "         online  returns  avg_rating\n",
      "131520       1        0        4.27\n",
      "131521       0        0        4.37\n",
      "131522       0        0        4.57\n",
      "131523       0        0        3.88\n",
      "131524       0        0        3.46\n",
      "store_02:\n",
      "        online  returns  avg_rating\n",
      "16440       0        0        4.34\n",
      "16441       1        0        4.25\n",
      "16442       0        0        4.60\n",
      "16443       1        0        4.23\n",
      "16444       1        0        4.31\n",
      "store_06:\n",
      "        online  returns  avg_rating\n",
      "82200       0        0        4.29\n",
      "82201       1        0        4.05\n",
      "82202       0        0        4.06\n",
      "82203       0        0        4.42\n",
      "82204       0        0        3.23\n"
     ]
    }
   ],
   "source": [
    "# Output examples.\n",
    "print('store_09:\\n',cx_dfs['store_09'].head())\n",
    "print('store_02:\\n',cx_dfs['store_02'].head())\n",
    "print('store_06:\\n',cx_dfs['store_06'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c68aac",
   "metadata": {},
   "source": [
    "Find the correlation coefficients between `online`, `returns`, and `avg_rating` for each store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e064324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_01 :\n",
      "               online   returns  avg_rating\n",
      "online      1.000000  0.007629    0.008385\n",
      "returns     0.007629  1.000000    0.005793\n",
      "avg_rating  0.008385  0.005793    1.000000\n",
      "store_02 :\n",
      "               online   returns  avg_rating\n",
      "online      1.000000 -0.000830    0.008339\n",
      "returns    -0.000830  1.000000    0.003312\n",
      "avg_rating  0.008339  0.003312    1.000000\n",
      "store_03 :\n",
      "               online   returns  avg_rating\n",
      "online      1.000000 -0.012437    0.003949\n",
      "returns    -0.012437  1.000000   -0.001758\n",
      "avg_rating  0.003949 -0.001758    1.000000\n",
      "store_04 :\n",
      "               online   returns  avg_rating\n",
      "online      1.000000  0.001898    0.007897\n",
      "returns     0.001898  1.000000   -0.005092\n",
      "avg_rating  0.007897 -0.005092    1.000000\n",
      "store_05 :\n",
      "               online   returns  avg_rating\n",
      "online      1.000000  0.009061    0.003746\n",
      "returns     0.009061  1.000000    0.000032\n",
      "avg_rating  0.003746  0.000032    1.000000\n",
      "store_06 :\n",
      "               online   returns  avg_rating\n",
      "online      1.000000 -0.000364    0.015562\n",
      "returns    -0.000364  1.000000    0.001300\n",
      "avg_rating  0.015562  0.001300    1.000000\n",
      "store_07 :\n",
      "               online   returns  avg_rating\n",
      "online      1.000000 -0.005830    0.003117\n",
      "returns    -0.005830  1.000000   -0.002768\n",
      "avg_rating  0.003117 -0.002768    1.000000\n",
      "store_08 :\n",
      "               online   returns  avg_rating\n",
      "online      1.000000 -0.002724   -0.002968\n",
      "returns    -0.002724  1.000000    0.011769\n",
      "avg_rating -0.002968  0.011769    1.000000\n",
      "store_09 :\n",
      "               online   returns  avg_rating\n",
      "online      1.000000 -0.000626    0.002548\n",
      "returns    -0.000626  1.000000   -0.011416\n",
      "avg_rating  0.002548 -0.011416    1.000000\n",
      "store_10 :\n",
      "               online   returns  avg_rating\n",
      "online      1.000000  0.006763    0.002992\n",
      "returns     0.006763  1.000000    0.006729\n",
      "avg_rating  0.002992  0.006729    1.000000\n"
     ]
    }
   ],
   "source": [
    "for store_id, df_cx in cx_dfs.items():\n",
    "    df_cx = df_cx[['online', 'returns', 'avg_rating']].corr()\n",
    "    cx_dfs[store_id] = df_cx\n",
    "    print(store_id,':\\n',df_cx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd17c5e",
   "metadata": {},
   "source": [
    "Average correlation values to find general insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7ce7bdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              online   returns  avg_rating\n",
      "online      1.000000  0.000254    0.005357\n",
      "returns     0.000254  1.000000    0.000790\n",
      "avg_rating  0.005357  0.000790    1.000000\n"
     ]
    }
   ],
   "source": [
    "cx_mat = []\n",
    "\n",
    "avg_cx_df = avg_corr(store_id, df_cx, cx_dfs, cx_mat)\n",
    "print(avg_cx_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e8304",
   "metadata": {},
   "source": [
    "As shown above, the correlation values is too low so we can say online transaction doesn't affect customer experience."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
